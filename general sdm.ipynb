{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9021be0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 只做一次\n",
    "# pip install geopandas libpysal linearmodels scipy pandas numpy\n",
    "from pathlib import Path   # ← 关键：先导入 Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "from libpysal import weights\n",
    "from libpysal.weights import Queen, KNN\n",
    "from scipy.sparse import identity\n",
    "from scipy.sparse.linalg import inv as spinv\n",
    "\n",
    "from linearmodels.iv import IV2SLS   # 用 2SLS/IV 估计 δ、ρ、β、θ（带双向固定效应）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4a7906",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_PANEL = Path(r\"D:\\Dissertation\\dissertation\\data 2\\data\\Without UK and Germany\\Final\\panel_long_merged_with_general.csv\")\n",
    "PATH_GEO   = Path(r\"D:\\Dissertation\\dissertation\\data 2\\data\\Without UK and Germany\\Final\\cleaned geo data\\NUTS2_2021.geojson\")\n",
    "OUT_DIR    = Path(r\"D:\\Dissertation\\dissertation\\data 2\\data\\Without UK and Germany\\Final\\moran\\SDM_Edit\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c4b49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── 读数据 ─────────────────────────────────────────────────────────────\n",
    "panel = pd.read_csv(PATH_PANEL)                       # 长表：NUTS_ID, year, ...\n",
    "nuts  = gpd.read_file(PATH_GEO)[[\"NUTS_ID\",\"geometry\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b215a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "panel = panel.rename(columns={\"region\": \"NUTS_ID\"})   # 关键一行\n",
    "panel[\"NUTS_ID\"] = panel[\"NUTS_ID\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97270191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用 general_per_million 生成 ln_x（自动把 ≤0 的设为 NaN，后面会 dropna）\n",
    "panel[\"general_per_million\"] = pd.to_numeric(panel[\"general_per_million\"], errors=\"coerce\")\n",
    "bad = (panel[\"general_per_million\"] <= 0).sum()\n",
    "print(f\"≤0 的条数：{bad}\")  # 仅提示你是否存在 0/负数\n",
    "panel[\"ln_x\"] = np.log(panel[\"general_per_million\"].where(panel[\"general_per_million\"] > 0, np.nan))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d51290",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用已对数的 y（log_gdp_pc）作为 ln_y\n",
    "panel[\"ln_y\"] = pd.to_numeric(panel[\"log_gdp_pc\"], errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8844167a",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = panel[\"general_per_million\"].astype(str).str.strip()\n",
    "\n",
    "# 1) 处理空白与常见“缺失占位”\n",
    "s = (s.replace({\"\": None, \"NA\": None, \"N/A\": None, \".\": None, \"-\": None, \"—\": None})\n",
    "       .str.replace(\"\\u00A0\", \"\", regex=False))  # 去掉不换行空格\n",
    "\n",
    "# 2) 先去掉千分位逗号（123,456 → 123456），再把小数逗号换成点（1,23 → 1.23）\n",
    "s = s.str.replace(r\",(?!\\d{3}\\b)\", \".\", regex=True)         # 小数逗号 → 点\n",
    "s = s.str.replace(r\"(?<=\\d),(?=\\d{3}\\b)\", \"\", regex=True)   # 千分位逗号 → 空\n",
    "\n",
    "# 3) 去掉除数字/点/负号外的杂字符（比如 <、~、%）\n",
    "s = s.str.replace(r\"[^0-9\\.\\-]\", \"\", regex=True)\n",
    "\n",
    "# 4) 转成数值\n",
    "panel[\"general_per_million\"] = pd.to_numeric(s, errors=\"coerce\")\n",
    "\n",
    "# 5) 统计问题行\n",
    "n_all  = len(s)\n",
    "n_na   = panel[\"general_per_million\"].isna().sum()\n",
    "n_le0  = (panel[\"general_per_million\"] <= 0).sum()\n",
    "print(f\"总行数: {n_all} | 解析失败(→NaN): {n_na} | ≤0 行: {n_le0}\")\n",
    "\n",
    "# 6) 生成 ln_x（把 ≤0 当缺失丢掉；若不想丢见下方“平移法”）\n",
    "panel[\"ln_x\"] = np.log(panel[\"general_per_million\"].where(panel[\"general_per_million\"] > 0, np.nan))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68bc8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_id = \"NUTS_ID\" if \"NUTS_ID\" in panel.columns else \"region\"\n",
    "panel[key_id] = panel[key_id].astype(str)\n",
    "panel[\"year\"] = pd.to_numeric(panel[\"year\"], errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "# === 2) 排序并生成滞后 ===============================================\n",
    "panel = panel.sort_values([key_id, \"year\"]).reset_index(drop=True)\n",
    "\n",
    "def add_lags(df, id_col, cols, lags=(1,2,3)):\n",
    "    for c in cols:\n",
    "        for L in lags:\n",
    "            df[f\"{c}_lag{L}\"] = df.groupby(id_col, observed=True)[c].shift(L)\n",
    "    return df\n",
    "\n",
    "panel = add_lags(panel, key_id, cols=[\"ln_y\", \"ln_x\"], lags=(1,2,3))\n",
    "\n",
    "# === 3) 快速查看（前几行） ===========================================\n",
    "cols_show = [\n",
    "    key_id, \"year\",\n",
    "    \"ln_y\",\"ln_y_lag1\",\"ln_y_lag2\",\"ln_y_lag3\",\n",
    "    \"ln_x\",\"ln_x_lag1\",\"ln_x_lag2\",\"ln_x_lag3\"\n",
    "]\n",
    "print(panel[cols_show].head(12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837bca70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Queen 邻接\n",
    "wq = Queen.from_dataframe(nuts, silence_warnings=True)\n",
    "\n",
    "# KNN6（补孤岛/断裂）\n",
    "wk = KNN.from_dataframe(nuts, k=6)\n",
    "\n",
    "# 合并 Queen 与 KNN 的邻接\n",
    "neighbors = {}\n",
    "for i in range(nuts.shape[0]):\n",
    "    qn = wq.neighbors.get(i, [])\n",
    "    kn = wk.neighbors.get(i, [])\n",
    "    neighbors[i] = sorted(set(qn + kn))\n",
    "\n",
    "W = weights.W(neighbors)     # 初始1/0权重\n",
    "W.transform = \"R\"            # 行标准化（常用）\n",
    "n = W.n\n",
    "\n",
    "# 建立从地区ID到W行号的映射\n",
    "nuts = nuts.reset_index(drop=True)\n",
    "id2row = dict(zip(nuts[\"NUTS_ID\"], nuts.index))\n",
    "panel[\"rid\"] = panel[\"NUTS_ID\"].map(id2row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a702bc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 时间滞后 y_{i,t-1}、y_{i,t-2}、y_{i,t-3}\n",
    "panel = panel.sort_values([\"NUTS_ID\",\"year\"])\n",
    "panel[\"ln_y_lag1\"] = panel.groupby(\"NUTS_ID\")[\"ln_y\"].shift(1)\n",
    "panel[\"ln_y_lag2\"] = panel.groupby(\"NUTS_ID\")[\"ln_y\"].shift(2)\n",
    "panel[\"ln_y_lag3\"] = panel.groupby(\"NUTS_ID\")[\"ln_y\"].shift(3)\n",
    "\n",
    "# 分年份做空间乘：Wy、Wx\n",
    "def add_spatial_lag(df, colname, newname):\n",
    "    out = []\n",
    "    for t, g in df.groupby(\"year\"):\n",
    "        v = g.set_index(\"rid\")[colname].reindex(range(n)).values\n",
    "        # 缺失填充为 0（更稳妥做法是先 dropna 再对齐；这里简单演示）\n",
    "        v = np.nan_to_num(v, nan=0.0)\n",
    "        lagv = W.sparse @ v\n",
    "        tmp = pd.DataFrame({\"rid\": range(n), \"year\": t, newname: lagv})\n",
    "        out.append(tmp)\n",
    "    out = pd.concat(out, ignore_index=True)\n",
    "    return df.merge(out, on=[\"rid\",\"year\"], how=\"left\")\n",
    "\n",
    "panel = add_spatial_lag(panel, \"ln_y\", \"wy\")     # W ln Y_it  —— ρ 的右手项\n",
    "panel = add_spatial_lag(panel, \"ln_x\", \"wx\")     # W ln X_it  —— θ 的右手项\n",
    "\n",
    "# 作为工具的高阶 W * X、W^2 * X，以及 W * y_{t-2}\n",
    "# W^2 * x\n",
    "def add_higher_order_Wx(df, base_name=\"ln_x\"):\n",
    "    # W^2：直接连乘稀疏矩阵\n",
    "    W2 = W.sparse @ W.sparse\n",
    "    out = []\n",
    "    for t, g in df.groupby(\"year\"):\n",
    "        x = g.set_index(\"rid\")[base_name].reindex(range(n)).values\n",
    "        x = np.nan_to_num(x, nan=0.0)\n",
    "        w2x = W2 @ x\n",
    "        tmp = pd.DataFrame({\"rid\": range(n), \"year\": t, \"w2_ln_x\": w2x})\n",
    "        out.append(tmp)\n",
    "    return df.merge(pd.concat(out, ignore_index=True), on=[\"rid\",\"year\"], how=\"left\")\n",
    "\n",
    "panel = add_higher_order_Wx(panel, \"ln_x\")\n",
    "\n",
    "# W * y_{t-2}\n",
    "panel[\"ln_y_lag2_tmp\"] = panel.groupby(\"NUTS_ID\")[\"ln_y\"].shift(2)\n",
    "panel = add_spatial_lag(panel, \"ln_y_lag2_tmp\", \"w_ln_y_lag2\")\n",
    "panel.drop(columns=[\"ln_y_lag2_tmp\"], inplace=True)\n",
    "\n",
    "# 回归可用的数据（去掉首两期缺滞后值的行）\n",
    "reg = panel.dropna(subset=[\"ln_y\",\"ln_x\",\"ln_y_lag1\",\"wy\",\"wx\",\"ln_y_lag2\",\"ln_y_lag3\",\"w2_ln_x\",\"w_ln_y_lag2\"]).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39af19c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 把 year / NUTS_ID 设为分类（固定效应用虚拟变量吸收）\n",
    "\n",
    "\n",
    "reg[\"year\"]    = reg[\"year\"].astype(\"category\")\n",
    "reg[\"NUTS_ID\"] = reg[\"NUTS_ID\"].astype(\"category\")\n",
    "\n",
    "# 公式： y ~ exog + [endog ~ instruments]\n",
    "# 这里 exog 有 ln_x, wx, 以及双向 FE：C(year) + C(NUTS_ID)\n",
    "# endog 是 ln_y_lag1（δ）和 wy（ρ）\n",
    "# instruments（排除工具）包括：w2_ln_x, ln_y_lag2, ln_y_lag3, w_ln_y_lag2\n",
    "formula = \"\"\"\n",
    "ln_y ~ 1 + C(year) + C(NUTS_ID) + ln_x + wx\n",
    "      + [ ln_y_lag1 + wy ~ w2_ln_x + ln_y_lag2 + ln_y_lag3 + w_ln_y_lag2 ]\n",
    "\"\"\"\n",
    "\n",
    "iv = IV2SLS.from_formula(formula, data=reg)\n",
    "res = iv.fit(cov_type=\"robust\")   # 或 \"clustered\", clusters=reg[\"NUTS_ID\"]\n",
    "print(res.summary)\n",
    "\n",
    "# 抽出四个系数\n",
    "delta  = res.params[\"ln_y_lag1\"]\n",
    "rho    = res.params[\"wy\"]\n",
    "beta   = res.params[\"ln_x\"]\n",
    "theta  = res.params[\"wx\"]\n",
    "delta, rho, beta, theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83d6fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "I = identity(n, format=\"csr\")\n",
    "Ws = W.sparse  # 行标准化后的稀疏矩阵\n",
    "\n",
    "# 稀疏逆（n≈~200 能承受；更大可以用求解-迹近似）\n",
    "M = spinv(I - rho * Ws)              # (I - ρW)^{-1}\n",
    "S0 = M @ (beta * I + theta * Ws)     # 当期乘数\n",
    "\n",
    "# 直接/总/间接（平均意义下）\n",
    "direct_short  = S0.diagonal().mean()\n",
    "total_short   = np.asarray(S0.sum(axis=1)).ravel().mean()\n",
    "indirect_short = total_short - direct_short\n",
    "\n",
    "# 长期（稳态）\n",
    "mult = 1.0 / (1.0 - delta)\n",
    "direct_long   = mult * direct_short\n",
    "indirect_long = mult * indirect_short\n",
    "total_long    = mult * total_short\n",
    "\n",
    "print(\"Short-run effects  (elasticities):\")\n",
    "print(f\"  Direct  = {direct_short:.4f}\")\n",
    "print(f\"  Indirect= {indirect_short:.4f}\")\n",
    "print(f\"  Total   = {total_short:.4f}\")\n",
    "\n",
    "print(\"\\nLong-run effects (× 1/(1-δ)):\")\n",
    "print(f\"  Direct  = {direct_long:.4f}\")\n",
    "print(f\"  Indirect= {indirect_long:.4f}\")\n",
    "print(f\"  Total   = {total_long:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b845f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "def stars(p):\n",
    "    return '***' if p < 0.01 else '**' if p < 0.05 else '*' if p < 0.10 else ''\n",
    "\n",
    "def sdm_impacts_with_se(res, W, x_name='ln_x', wy_name='wy', wx_name='wx', lagy_name='ln_y_lag1',\n",
    "                        B=3000, seed=2025):\n",
    "    \"\"\"返回 impacts（SR/LR）的点估计、SE、p值、95%CI 以及占比AIE/ATE（含区间）\"\"\"\n",
    "    n = W.n\n",
    "    I = identity(n, format='csr')\n",
    "    S = W.sparse\n",
    "\n",
    "    p = res.params\n",
    "    has_delta = lagy_name in p.index\n",
    "    # 读参数（容错：x_name 换成 'x' 也能取到）\n",
    "    rho   = float(p[wy_name])\n",
    "    beta  = float(p[x_name] if x_name in p.index else p['x'])\n",
    "    theta = float(p[wx_name])\n",
    "    delta = float(p[lagy_name]) if has_delta else 0.0\n",
    "\n",
    "    # —— 点估计（SR/LR）\n",
    "    M  = spinv(I - rho * S)\n",
    "    S0 = M @ (beta * I + theta * S)\n",
    "    direct_SR   = S0.diagonal().mean()\n",
    "    total_SR    = np.asarray(S0.sum(axis=1)).ravel().mean()\n",
    "    indirect_SR = total_SR - direct_SR\n",
    "    mult        = 1.0 / (1.0 - delta) if has_delta else 1.0\n",
    "    direct_LR, indirect_LR, total_LR = mult*direct_SR, mult*indirect_SR, mult*total_SR\n",
    "\n",
    "    # —— 参数模拟（Krinsky–Robb）\n",
    "    names = [wy_name, x_name if x_name in p.index else 'x', wx_name] + ([lagy_name] if has_delta else [])\n",
    "    cov   = res.cov.loc[names, names].values\n",
    "    mean  = p[names].values\n",
    "\n",
    "    rng   = np.random.default_rng(seed)\n",
    "    draws = rng.multivariate_normal(mean, cov, size=B)\n",
    "\n",
    "    SR_dir=[]; SR_ind=[]; SR_tot=[]\n",
    "    LR_dir=[]; LR_ind=[]; LR_tot=[]\n",
    "    for d in draws:\n",
    "        if has_delta:\n",
    "            rho_b, beta_b, theta_b, delta_b = d\n",
    "            mult_b = 1.0 / (1.0 - delta_b) if abs(delta_b) < 0.999 else np.nan\n",
    "        else:\n",
    "            rho_b, beta_b, theta_b = d\n",
    "            mult_b = 1.0\n",
    "        try:\n",
    "            Mb = spinv(I - rho_b * S)\n",
    "        except Exception:\n",
    "            continue\n",
    "        S0b = Mb @ (beta_b * I + theta_b * S)\n",
    "        d_sr = S0b.diagonal().mean()\n",
    "        t_sr = np.asarray(S0b.sum(axis=1)).ravel().mean()\n",
    "        i_sr = t_sr - d_sr\n",
    "        SR_dir.append(d_sr); SR_ind.append(i_sr); SR_tot.append(t_sr)\n",
    "        LR_dir.append(mult_b*d_sr); LR_ind.append(mult_b*i_sr); LR_tot.append(mult_b*t_sr)\n",
    "\n",
    "    def _summ(samples, est):\n",
    "        arr = np.asarray(samples)\n",
    "        se  = np.nanstd(arr, ddof=1)\n",
    "        z   = est / se\n",
    "        p   = 2 * (1 - norm.cdf(abs(z)))\n",
    "        lo, hi = np.nanpercentile(arr, [2.5, 97.5])\n",
    "        return dict(est=est, se=se, p=p, lo=lo, hi=hi)\n",
    "\n",
    "    out = {\n",
    "        ('Direct','SR'): _summ(SR_dir, direct_SR),\n",
    "        ('Indirect','SR'): _summ(SR_ind, indirect_SR),\n",
    "        ('Total','SR'): _summ(SR_tot, total_SR),\n",
    "        ('Direct','LR'): _summ(LR_dir, direct_LR),\n",
    "        ('Indirect','LR'): _summ(LR_ind, indirect_LR),\n",
    "        ('Total','LR'): _summ(LR_tot, total_LR),\n",
    "        ('Share','SR'):  _summ(np.asarray(SR_ind)/np.asarray(SR_tot), indirect_SR/total_SR),\n",
    "        ('Share','LR'):  _summ(np.asarray(LR_ind)/np.asarray(LR_tot), indirect_LR/total_LR)\n",
    "    }\n",
    "    return out, has_delta\n",
    "# --- helper for stars (if not already defined) ---\n",
    "def stars(p):\n",
    "    return '***' if p < 0.01 else '**' if p < 0.05 else '*' if p < 0.10 else ''\n",
    "\n",
    "# === 1) Impacts ===\n",
    "imp, has_delta = sdm_impacts_with_se(\n",
    "    res, W, x_name='ln_x', wy_name='wy', wx_name='wx', lagy_name='ln_y_lag1'\n",
    ")\n",
    "\n",
    "# === 2) Panel A: coefficients ===\n",
    "coef_rows = []\n",
    "labels = {\n",
    "    'wy'        : 'ρ · W ln Y',\n",
    "    'ln_x'      : 'β · ln X',\n",
    "    'x'         : 'β · ln X',\n",
    "    'wx'        : 'θ · W ln X',\n",
    "    'ln_y_lag1' : 'δ · ln Y_{t−1}'\n",
    "}\n",
    "for name in ['wy', 'ln_x' if 'ln_x' in res.params.index else 'x', 'wx'] + (['ln_y_lag1'] if has_delta else []):\n",
    "    coef_rows.append({\n",
    "        'Variable'   : labels[name],\n",
    "        'Coef.'      : res.params[name],\n",
    "        'Std. Error' : res.std_errors[name],\n",
    "        'p-value'    : res.pvalues[name]\n",
    "    })\n",
    "panelA = pd.DataFrame(coef_rows)\n",
    "\n",
    "# sample/setup info\n",
    "key_id = 'NUTS_ID' if 'NUTS_ID' in panel.columns else 'region'\n",
    "try:\n",
    "    N = int(getattr(res, 'nobs', None) or reg.shape[0])\n",
    "except NameError:\n",
    "    N = int(getattr(res, 'nobs', np.nan))\n",
    "G = int(reg[key_id].nunique())\n",
    "T = int(reg['year'].nunique())\n",
    "\n",
    "info_rows = pd.DataFrame([\n",
    "    {'Variable':'Region FE / Year FE', 'Coef.':'Yes / Yes', 'Std. Error':'', 'p-value':''},\n",
    "    {'Variable':'Obs. N; Regions G; Years T', 'Coef.':f'{N}; {G}; {T}', 'Std. Error':'', 'p-value':''}\n",
    "])\n",
    "panelA_full = pd.concat([panelA, info_rows], ignore_index=True)\n",
    "\n",
    "# === 3) Panel B: impacts (short/long with SE & p) ===\n",
    "def fmt(cell):\n",
    "    return f\"{cell['est']:.4f} ({cell['se']:.4f}){stars(cell['p'])}\"\n",
    "\n",
    "panelB = pd.DataFrame({\n",
    "    'Effect'          : ['Direct (ADE)','Indirect (AIE)','Total (ATE)','Spillover share (AIE/ATE)'],\n",
    "    'Short-run (SR)'  : [fmt(imp[('Direct','SR')]),\n",
    "                         fmt(imp[('Indirect','SR')]),\n",
    "                         fmt(imp[('Total','SR')]),\n",
    "                         f\"{imp[('Share','SR')]['est']:.3f} [{imp[('Share','SR')]['lo']:.3f},{imp[('Share','SR')]['hi']:.3f}]\"],\n",
    "    'Long-run (LR)'   : [fmt(imp[('Direct','LR')]),\n",
    "                         fmt(imp[('Indirect','LR')]),\n",
    "                         fmt(imp[('Total','LR')]),\n",
    "                         f\"{imp[('Share','LR')]['est']:.3f} [{imp[('Share','LR')]['lo']:.3f},{imp[('Share','LR')]['hi']:.3f}]\"]\n",
    "})\n",
    "\n",
    "# === 4) Combine and export ===\n",
    "empty = pd.DataFrame([{'Variable':'', 'Coef.':'', 'Std. Error':'', 'p-value':''}])\n",
    "\n",
    "combined = pd.concat([\n",
    "    pd.DataFrame([{'Variable':'Panel A: Coefficients (dependent variable ln Y)', 'Coef.':'', 'Std. Error':'', 'p-value':''}]),\n",
    "    panelA_full,\n",
    "    empty,\n",
    "    pd.DataFrame([{'Variable':'Panel B: LeSage–Pace impacts (ln X → ln Y, elasticities)', 'Coef.':'', 'Std. Error':'', 'p-value':''}]),\n",
    "    panelB.rename(columns={'Effect':'Variable', 'Short-run (SR)':'Coef.', 'Long-run (LR)':'Std. Error'}).assign(**{'p-value':''})\n",
    "], ignore_index=True)\n",
    "\n",
    "# CSV\n",
    "combined.to_csv(OUT_DIR / \"SDM_general_gdp2.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "# Excel (engine fallback: xlsxwriter -> openpyxl; if neither, only CSV)\n",
    "excel_path = OUT_DIR / \"SDM_general_gdp2.xlsx\"\n",
    "engine = None\n",
    "try:\n",
    "    import xlsxwriter  # noqa\n",
    "    engine = \"xlsxwriter\"\n",
    "except ModuleNotFoundError:\n",
    "    try:\n",
    "        import openpyxl  # noqa\n",
    "        engine = \"openpyxl\"\n",
    "    except ModuleNotFoundError:\n",
    "        engine = None\n",
    "\n",
    "if engine:\n",
    "    with pd.ExcelWriter(excel_path, engine=engine) as w:\n",
    "        combined.to_excel(w, index=False, sheet_name=\"SDM\")\n",
    "    print(f\"Exported Excel (engine={engine}): {excel_path}\")\n",
    "else:\n",
    "    print(\"xlsxwriter/openpyxl not installed; exported CSV only. Install one if you need .xlsx.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0dbc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 只做一次\n",
    "# pip install geopandas libpysal linearmodels scipy pandas numpy\n",
    "from pathlib import Path   # ← 关键：先导入 Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "from libpysal import weights\n",
    "from libpysal.weights import Queen, KNN\n",
    "from scipy.sparse import identity\n",
    "from scipy.sparse.linalg import inv as spinv\n",
    "\n",
    "from linearmodels.iv import IV2SLS   # 用 2SLS/IV 估计 δ、ρ、β、θ（带双向固定效应）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8ef2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_PANEL = Path(r\"D:\\Dissertation\\dissertation\\data 2\\data\\Without UK and Germany\\Final\\panel_long_merged_with_general.csv\")\n",
    "PATH_GEO   = Path(r\"D:\\Dissertation\\dissertation\\data 2\\data\\Without UK and Germany\\Final\\cleaned geo data\\NUTS2_2021.geojson\")\n",
    "OUT_DIR    = Path(r\"D:\\Dissertation\\dissertation\\data 2\\data\\Without UK and Germany\\Final\\moran\\SDM_Edit\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ── 读数据 ─────────────────────────────────────────────────────────────\n",
    "panel = pd.read_csv(PATH_PANEL)                       # 长表：NUTS_ID, year, ...\n",
    "nuts  = gpd.read_file(PATH_GEO)[[\"NUTS_ID\",\"geometry\"]]\n",
    "\n",
    "\n",
    "panel = panel.rename(columns={\"region\": \"NUTS_ID\"})   # 关键一行\n",
    "panel[\"NUTS_ID\"] = panel[\"NUTS_ID\"].astype(str)\n",
    "\n",
    "# 用 general_per_million 生成 ln_x（自动把 ≤0 的设为 NaN，后面会 dropna）\n",
    "panel[\"general_per_million\"] = pd.to_numeric(panel[\"general_per_million\"], errors=\"coerce\")\n",
    "bad = (panel[\"vet_per_million\"] <= 0).sum()\n",
    "print(f\"≤0 的条数：{bad}\")  # 仅提示你是否存在 0/负数\n",
    "panel[\"ln_x\"] = np.log(panel[\"general_per_million\"].where(panel[\"general_per_million\"] > 0, np.nan))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d719a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用已对数的 y（log_gdp_pc）作为 ln_y\n",
    "panel[\"employment_rate\"] = pd.to_numeric(panel[\"employment_rate\"], errors=\"coerce\")\n",
    "\n",
    "er = panel[\"employment_rate\"]\n",
    "# 自动识别：若最大值>1，说明是百分数，先 /100\n",
    "er = er/100.0 if er.dropna().max() > 1.0000001 else er\n",
    "\n",
    "print(\"employment_rate 中 ≤0 的条数：\", (er <= 0).sum())\n",
    "panel[\"ln_y\"] = np.log(er.where(er > 0, np.nan))   # ln(employment_rate)\n",
    "\n",
    "s = panel[\"general_per_million\"].astype(str).str.strip()\n",
    "\n",
    "# 1) 处理空白与常见“缺失占位”\n",
    "s = (s.replace({\"\": None, \"NA\": None, \"N/A\": None, \".\": None, \"-\": None, \"—\": None})\n",
    "       .str.replace(\"\\u00A0\", \"\", regex=False))  # 去掉不换行空格\n",
    "\n",
    "# 2) 先去掉千分位逗号（123,456 → 123456），再把小数逗号换成点（1,23 → 1.23）\n",
    "s = s.str.replace(r\",(?!\\d{3}\\b)\", \".\", regex=True)         # 小数逗号 → 点\n",
    "s = s.str.replace(r\"(?<=\\d),(?=\\d{3}\\b)\", \"\", regex=True)   # 千分位逗号 → 空\n",
    "\n",
    "# 3) 去掉除数字/点/负号外的杂字符（比如 <、~、%）\n",
    "s = s.str.replace(r\"[^0-9\\.\\-]\", \"\", regex=True)\n",
    "\n",
    "# 4) 转成数值\n",
    "panel[\"general_per_million\"] = pd.to_numeric(s, errors=\"coerce\")\n",
    "\n",
    "# 5) 统计问题行\n",
    "n_all  = len(s)\n",
    "n_na   = panel[\"general_per_million\"].isna().sum()\n",
    "n_le0  = (panel[\"general_per_million\"] <= 0).sum()\n",
    "print(f\"总行数: {n_all} | 解析失败(→NaN): {n_na} | ≤0 行: {n_le0}\")\n",
    "\n",
    "# 6) 生成 ln_x（把 ≤0 当缺失丢掉；若不想丢见下方“平移法”）\n",
    "panel[\"ln_x\"] = np.log(panel[\"general_per_million\"].where(panel[\"general_per_million\"] > 0, np.nan))\n",
    "                                                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e089253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用 general_per_million 生成 ln_x（自动把 ≤0 的设为 NaN，后面会 dropna）\n",
    "panel[\"general_per_million\"] = pd.to_numeric(panel[\"general_per_million\"], errors=\"coerce\")\n",
    "bad = (panel[\"general_per_million\"] <= 0).sum()\n",
    "print(f\"≤0 的条数：{bad}\")  # 仅提示你是否存在 0/负数\n",
    "panel[\"ln_x\"] = np.log(panel[\"general_per_million\"].where(panel[\"general_per_million\"] > 0, np.nan))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba55ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_id = \"NUTS_ID\" if \"NUTS_ID\" in panel.columns else \"region\"\n",
    "panel[key_id] = panel[key_id].astype(str)\n",
    "panel[\"year\"] = pd.to_numeric(panel[\"year\"], errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "# === 2) 排序并生成滞后 ===============================================\n",
    "panel = panel.sort_values([key_id, \"year\"]).reset_index(drop=True)\n",
    "\n",
    "def add_lags(df, id_col, cols, lags=(1,2,3)):\n",
    "    for c in cols:\n",
    "        for L in lags:\n",
    "            df[f\"{c}_lag{L}\"] = df.groupby(id_col, observed=True)[c].shift(L)\n",
    "    return df\n",
    "\n",
    "panel = add_lags(panel, key_id, cols=[\"ln_y\", \"ln_x\"], lags=(1,2,3))\n",
    "\n",
    "# === 3) 快速查看（前几行） ===========================================\n",
    "cols_show = [\n",
    "    key_id, \"year\",\n",
    "    \"ln_y\",\"ln_y_lag1\",\"ln_y_lag2\",\"ln_y_lag3\",\n",
    "    \"ln_x\",\"ln_x_lag1\",\"ln_x_lag2\",\"ln_x_lag3\"\n",
    "]\n",
    "print(panel[cols_show].head(12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c761b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Queen 邻接\n",
    "wq = Queen.from_dataframe(nuts, silence_warnings=True)\n",
    "\n",
    "# KNN6（补孤岛/断裂）\n",
    "wk = KNN.from_dataframe(nuts, k=6)\n",
    "\n",
    "# 合并 Queen 与 KNN 的邻接\n",
    "neighbors = {}\n",
    "for i in range(nuts.shape[0]):\n",
    "    qn = wq.neighbors.get(i, [])\n",
    "    kn = wk.neighbors.get(i, [])\n",
    "    neighbors[i] = sorted(set(qn + kn))\n",
    "\n",
    "W = weights.W(neighbors)     # 初始1/0权重\n",
    "W.transform = \"R\"            # 行标准化（常用）\n",
    "n = W.n\n",
    "\n",
    "# 建立从地区ID到W行号的映射\n",
    "nuts = nuts.reset_index(drop=True)\n",
    "id2row = dict(zip(nuts[\"NUTS_ID\"], nuts.index))\n",
    "panel[\"rid\"] = panel[\"NUTS_ID\"].map(id2row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d0490f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 时间滞后 y_{i,t-1}、y_{i,t-2}、y_{i,t-3}\n",
    "panel = panel.sort_values([\"NUTS_ID\",\"year\"])\n",
    "panel[\"ln_y_lag1\"] = panel.groupby(\"NUTS_ID\")[\"ln_y\"].shift(1)\n",
    "panel[\"ln_y_lag2\"] = panel.groupby(\"NUTS_ID\")[\"ln_y\"].shift(2)\n",
    "panel[\"ln_y_lag3\"] = panel.groupby(\"NUTS_ID\")[\"ln_y\"].shift(3)\n",
    "\n",
    "# 分年份做空间乘：Wy、Wx\n",
    "def add_spatial_lag(df, colname, newname):\n",
    "    out = []\n",
    "    for t, g in df.groupby(\"year\"):\n",
    "        v = g.set_index(\"rid\")[colname].reindex(range(n)).values\n",
    "        # 缺失填充为 0（更稳妥做法是先 dropna 再对齐；这里简单演示）\n",
    "        v = np.nan_to_num(v, nan=0.0)\n",
    "        lagv = W.sparse @ v\n",
    "        tmp = pd.DataFrame({\"rid\": range(n), \"year\": t, newname: lagv})\n",
    "        out.append(tmp)\n",
    "    out = pd.concat(out, ignore_index=True)\n",
    "    return df.merge(out, on=[\"rid\",\"year\"], how=\"left\")\n",
    "\n",
    "panel = add_spatial_lag(panel, \"ln_y\", \"wy\")     # W ln Y_it  —— ρ 的右手项\n",
    "panel = add_spatial_lag(panel, \"ln_x\", \"wx\")     # W ln X_it  —— θ 的右手项\n",
    "\n",
    "# 作为工具的高阶 W * X、W^2 * X，以及 W * y_{t-2}\n",
    "# W^2 * x\n",
    "def add_higher_order_Wx(df, base_name=\"ln_x\"):\n",
    "    # W^2：直接连乘稀疏矩阵\n",
    "    W2 = W.sparse @ W.sparse\n",
    "    out = []\n",
    "    for t, g in df.groupby(\"year\"):\n",
    "        x = g.set_index(\"rid\")[base_name].reindex(range(n)).values\n",
    "        x = np.nan_to_num(x, nan=0.0)\n",
    "        w2x = W2 @ x\n",
    "        tmp = pd.DataFrame({\"rid\": range(n), \"year\": t, \"w2_ln_x\": w2x})\n",
    "        out.append(tmp)\n",
    "    return df.merge(pd.concat(out, ignore_index=True), on=[\"rid\",\"year\"], how=\"left\")\n",
    "\n",
    "panel = add_higher_order_Wx(panel, \"ln_x\")\n",
    "\n",
    "# W * y_{t-2}\n",
    "panel[\"ln_y_lag2_tmp\"] = panel.groupby(\"NUTS_ID\")[\"ln_y\"].shift(2)\n",
    "panel = add_spatial_lag(panel, \"ln_y_lag2_tmp\", \"w_ln_y_lag2\")\n",
    "panel.drop(columns=[\"ln_y_lag2_tmp\"], inplace=True)\n",
    "\n",
    "# 回归可用的数据（去掉首两期缺滞后值的行）\n",
    "reg = panel.dropna(subset=[\"ln_y\",\"ln_x\",\"ln_y_lag1\",\"wy\",\"wx\",\"ln_y_lag2\",\"ln_y_lag3\",\"w2_ln_x\",\"w_ln_y_lag2\"]).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf13401",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 把 year / NUTS_ID 设为分类（固定效应用虚拟变量吸收）\n",
    "\n",
    "\n",
    "reg[\"year\"]    = reg[\"year\"].astype(\"category\")\n",
    "reg[\"NUTS_ID\"] = reg[\"NUTS_ID\"].astype(\"category\")\n",
    "\n",
    "# 公式： y ~ exog + [endog ~ instruments]\n",
    "# 这里 exog 有 ln_x, wx, 以及双向 FE：C(year) + C(NUTS_ID)\n",
    "# endog 是 ln_y_lag1（δ）和 wy（ρ）\n",
    "# instruments（排除工具）包括：w2_ln_x, ln_y_lag2, ln_y_lag3, w_ln_y_lag2\n",
    "formula = \"\"\"\n",
    "ln_y ~ 1 + C(year) + C(NUTS_ID) + ln_x + wx\n",
    "      + [ ln_y_lag1 + wy ~ w2_ln_x + ln_y_lag2 + ln_y_lag3 + w_ln_y_lag2 ]\n",
    "\"\"\"\n",
    "\n",
    "iv = IV2SLS.from_formula(formula, data=reg)\n",
    "res = iv.fit(cov_type=\"robust\")   # 或 \"clustered\", clusters=reg[\"NUTS_ID\"]\n",
    "print(res.summary)\n",
    "\n",
    "# 抽出四个系数\n",
    "rho    = res.params[\"wy\"]\n",
    "beta   = res.params[\"ln_x\"]\n",
    "theta  = res.params[\"wx\"]\n",
    "delta, rho, beta, theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a14f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "I = identity(n, format=\"csr\")\n",
    "Ws = W.sparse  # 行标准化后的稀疏矩阵\n",
    "\n",
    "# 稀疏逆（n≈~200 能承受；更大可以用求解-迹近似）\n",
    "M = spinv(I - rho * Ws)              # (I - ρW)^{-1}\n",
    "S0 = M @ (beta * I + theta * Ws)     # 当期乘数\n",
    "\n",
    "# 直接/总/间接（平均意义下）\n",
    "direct_short  = S0.diagonal().mean()\n",
    "total_short   = np.asarray(S0.sum(axis=1)).ravel().mean()\n",
    "indirect_short = total_short - direct_short\n",
    "\n",
    "# 长期（稳态）\n",
    "mult = 1.0 / (1.0 - delta)\n",
    "direct_long   = mult * direct_short\n",
    "indirect_long = mult * indirect_short\n",
    "total_long    = mult * total_short\n",
    "\n",
    "print(\"Short-run effects  (elasticities):\")\n",
    "print(f\"  Direct  = {direct_short:.4f}\")\n",
    "print(f\"  Indirect= {indirect_short:.4f}\")\n",
    "print(f\"  Total   = {total_short:.4f}\")\n",
    "\n",
    "print(\"\\nLong-run effects (× 1/(1-δ)):\")\n",
    "print(f\"  Direct  = {direct_long:.4f}\")\n",
    "print(f\"  Indirect= {indirect_long:.4f}\")\n",
    "print(f\"  Total   = {total_long:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8a1aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- helper for stars (if not already defined) ---\n",
    "def stars(p):\n",
    "    return '***' if p < 0.01 else '**' if p < 0.05 else '*' if p < 0.10 else ''\n",
    "\n",
    "# === 1) Impacts ===\n",
    "imp, has_delta = sdm_impacts_with_se(\n",
    "    res, W, x_name='ln_x', wy_name='wy', wx_name='wx', lagy_name='ln_y_lag1'\n",
    ")\n",
    "\n",
    "# === 2) Panel A: coefficients ===\n",
    "coef_rows = []\n",
    "labels = {\n",
    "    'wy'        : 'ρ · W ln Y',\n",
    "    'ln_x'      : 'β · ln X',\n",
    "    'x'         : 'β · ln X',\n",
    "    'wx'        : 'θ · W ln X',\n",
    "    'ln_y_lag1' : 'δ · ln Y_{t−1}'\n",
    "}\n",
    "for name in ['wy', 'ln_x' if 'ln_x' in res.params.index else 'x', 'wx'] + (['ln_y_lag1'] if has_delta else []):\n",
    "    coef_rows.append({\n",
    "        'Variable'   : labels[name],\n",
    "        'Coef.'      : res.params[name],\n",
    "        'Std. Error' : res.std_errors[name],\n",
    "        'p-value'    : res.pvalues[name]\n",
    "    })\n",
    "panelA = pd.DataFrame(coef_rows)\n",
    "\n",
    "# sample/setup info\n",
    "key_id = 'NUTS_ID' if 'NUTS_ID' in panel.columns else 'region'\n",
    "try:\n",
    "    N = int(getattr(res, 'nobs', None) or reg.shape[0])\n",
    "except NameError:\n",
    "    N = int(getattr(res, 'nobs', np.nan))\n",
    "G = int(reg[key_id].nunique())\n",
    "T = int(reg['year'].nunique())\n",
    "\n",
    "info_rows = pd.DataFrame([\n",
    "    {'Variable':'Region FE / Year FE', 'Coef.':'Yes / Yes', 'Std. Error':'', 'p-value':''},\n",
    "    {'Variable':'Obs. N; Regions G; Years T', 'Coef.':f'{N}; {G}; {T}', 'Std. Error':'', 'p-value':''}\n",
    "])\n",
    "panelA_full = pd.concat([panelA, info_rows], ignore_index=True)\n",
    "\n",
    "# === 3) Panel B: impacts (short/long with SE & p) ===\n",
    "def fmt(cell):\n",
    "    return f\"{cell['est']:.4f} ({cell['se']:.4f}){stars(cell['p'])}\"\n",
    "\n",
    "panelB = pd.DataFrame({\n",
    "    'Effect'          : ['Direct (ADE)','Indirect (AIE)','Total (ATE)','Spillover share (AIE/ATE)'],\n",
    "    'Short-run (SR)'  : [fmt(imp[('Direct','SR')]),\n",
    "                         fmt(imp[('Indirect','SR')]),\n",
    "                         fmt(imp[('Total','SR')]),\n",
    "                         f\"{imp[('Share','SR')]['est']:.3f} [{imp[('Share','SR')]['lo']:.3f},{imp[('Share','SR')]['hi']:.3f}]\"],\n",
    "    'Long-run (LR)'   : [fmt(imp[('Direct','LR')]),\n",
    "                         fmt(imp[('Indirect','LR')]),\n",
    "                         fmt(imp[('Total','LR')]),\n",
    "                         f\"{imp[('Share','LR')]['est']:.3f} [{imp[('Share','LR')]['lo']:.3f},{imp[('Share','LR')]['hi']:.3f}]\"]\n",
    "})\n",
    "\n",
    "# === 4) Combine and export ===\n",
    "empty = pd.DataFrame([{'Variable':'', 'Coef.':'', 'Std. Error':'', 'p-value':''}])\n",
    "\n",
    "combined = pd.concat([\n",
    "    pd.DataFrame([{'Variable':'Panel A: Coefficients (dependent variable ln Y)', 'Coef.':'', 'Std. Error':'', 'p-value':''}]),\n",
    "    panelA_full,\n",
    "    empty,\n",
    "    pd.DataFrame([{'Variable':'Panel B: LeSage–Pace impacts (ln X → ln Y, elasticities)', 'Coef.':'', 'Std. Error':'', 'p-value':''}]),\n",
    "    panelB.rename(columns={'Effect':'Variable', 'Short-run (SR)':'Coef.', 'Long-run (LR)':'Std. Error'}).assign(**{'p-value':''})\n",
    "], ignore_index=True)\n",
    "\n",
    "# CSV\n",
    "combined.to_csv(OUT_DIR / \"SDM_general_vet_em3.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "# Excel (engine fallback: xlsxwriter -> openpyxl; if neither, only CSV)\n",
    "excel_path = OUT_DIR / \"SDM_general_vet_em3.xlsx\"\n",
    "engine = None\n",
    "try:\n",
    "    import xlsxwriter  # noqa\n",
    "    engine = \"xlsxwriter\"\n",
    "except ModuleNotFoundError:\n",
    "    try:\n",
    "        import openpyxl  # noqa\n",
    "        engine = \"openpyxl\"\n",
    "    except ModuleNotFoundError:\n",
    "        engine = None\n",
    "\n",
    "if engine:\n",
    "    with pd.ExcelWriter(excel_path, engine=engine) as w:\n",
    "        combined.to_excel(w, index=False, sheet_name=\"SDM\")\n",
    "    print(f\"Exported Excel (engine={engine}): {excel_path}\")\n",
    "else:\n",
    "    print(\"xlsxwriter/openpyxl not installed; exported CSV only. Install one if you need .xlsx.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
