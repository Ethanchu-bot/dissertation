{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2364e95d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "geoè¿‡æ»¤åå‰©ä½™åŒºåŸŸæ•°: 204\n",
      "è¯†åˆ«å‡ºå­¤å²›æ•°é‡: 9\n",
      "å­¤å²›ç¤ºä¾‹: ['EL41', 'EL42', 'EL43', 'EL62', 'ES53', 'FI20', 'FRM0', 'ITG1', 'ITG2'] \n",
      "âœ… å·²ä¿å­˜å»å­¤å²›åçš„é¢æ¿: D:\\Dissertation\\dissertation\\data 2\\data\\Without UK and Germany\\Final\\filtered_by_islands\\panel_long_no_islands.csv | è¡Œæ•°: 2145\n",
      "âœ… å·²ä¿å­˜å»å­¤å²›åçš„ geo: D:\\Dissertation\\dissertation\\data 2\\data\\Without UK and Germany\\Final\\filtered_by_islands\\NUTS2_2021_no_islands.gpkg | åŒºåŸŸæ•°: 195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Python\\Lib\\site-packages\\libpysal\\weights\\contiguity.py:347: UserWarning: The weights matrix is not fully connected: \n",
      " There are 14 disconnected components.\n",
      " There are 9 islands with ids: ES53, EL62, EL42, EL41, EL43, FI20, ITG2, FRM0, ITG1.\n",
      "  W.__init__(self, neighbors, ids=ids, **kw)\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from libpysal.weights import Queen\n",
    "\n",
    "# ---------- è·¯å¾„ ----------\n",
    "GEO_PATH_IN   = r\"D:\\Dissertation\\dissertation\\data 2\\data\\Without UK and Germany\\Final\\cleaned geo data\\NUTS2_2021.gpkg\"\n",
    "PANEL_PATH_IN = r\"D:\\Dissertation\\dissertation\\data 2\\data\\Without UK and Germany\\Final\\panel_long_merged.csv\"\n",
    "\n",
    "OUT_DIR        = Path(r\"D:\\Dissertation\\dissertation\\data 2\\data\\Without UK and Germany\\Final\\filtered_by_islands\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "PANEL_PATH_OUT = OUT_DIR / \"panel_long_no_islands.csv\"\n",
    "GEO_PATH_OUT   = OUT_DIR / \"NUTS2_2021_no_islands.gpkg\"\n",
    "DROPPED_IDS_TXT= OUT_DIR / \"islands_dropped.txt\"\n",
    "\n",
    "def detect_geo_id(gdf: gpd.GeoDataFrame) -> str:\n",
    "    for c in [\"NUTS_ID\",\"nuts_id\",\"NUTS_ID_2021\",\"region\",\"geo\",\"code\",\"id\"]:\n",
    "        if c in gdf.columns: return c\n",
    "    return [c for c in gdf.columns if c != gdf.geometry.name][0]\n",
    "\n",
    "# è¯»æ•°æ®\n",
    "gdf = gpd.read_file(GEO_PATH_IN)\n",
    "gid = detect_geo_id(gdf)\n",
    "\n",
    "# ç»Ÿä¸€ IDï¼ˆæ³¨æ„ .str.upper()ï¼‰\n",
    "gdf[\"__id__\"] = (\n",
    "    gdf[gid]\n",
    "    .astype(\"string\")\n",
    "    .str.strip()\n",
    "    .str.upper()\n",
    ")\n",
    "\n",
    "pdf = pd.read_csv(PANEL_PATH_IN, encoding=\"utf-8-sig\")\n",
    "if \"region\" not in pdf.columns:\n",
    "    raise ValueError(\"é¢æ¿ç¼ºå°‘ 'region' åˆ—\")\n",
    "\n",
    "pdf[\"region\"] = (\n",
    "    pdf[\"region\"]\n",
    "    .astype(\"string\")\n",
    "    .str.strip()\n",
    "    .str.upper()\n",
    ")\n",
    "\n",
    "# Step 1: geo å…ˆæŒ‰ csv è¿‡æ»¤\n",
    "keep_regions = set(pdf[\"region\"].dropna().unique())\n",
    "gdf_sub = gdf[gdf[\"__id__\"].isin(keep_regions)].copy()\n",
    "print(f\"geoè¿‡æ»¤åå‰©ä½™åŒºåŸŸæ•°: {len(gdf_sub)}\")\n",
    "\n",
    "# Step 2: Queen æ‰¾å­¤å²›\n",
    "from libpysal.weights import Queen\n",
    "import numpy as np\n",
    "\n",
    "# æ–¹å¼ä¸€ï¼šä¿ç•™ ids\n",
    "wq = Queen.from_dataframe(gdf_sub, ids=gdf_sub[\"__id__\"].tolist())\n",
    "\n",
    "first = next(iter(wq.islands), None)\n",
    "if isinstance(first, (int, np.integer)):\n",
    "    island_ids = gdf_sub[\"__id__\"].iloc[list(wq.islands)].tolist()\n",
    "else:\n",
    "    island_ids = list(wq.islands)\n",
    "\n",
    "print(f\"è¯†åˆ«å‡ºå­¤å²›æ•°é‡: {len(island_ids)}\")\n",
    "print(\"å­¤å²›ç¤ºä¾‹:\", sorted(island_ids)[:12], \"...\" if len(island_ids)>12 else \"\")\n",
    "\n",
    "\n",
    "with open(DROPPED_IDS_TXT, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"Queen islands (degree=0) dropped:\\n\")\n",
    "    for rid in sorted(island_ids):\n",
    "        f.write(rid + \"\\n\")\n",
    "\n",
    "# Step 3: ä» CSV ä¸ GEO éƒ½åˆ é™¤å­¤å²›å¹¶å¦å­˜\n",
    "isles = set(island_ids)\n",
    "pdf_no_islands = pdf[~pdf[\"region\"].isin(isles)].copy()\n",
    "pdf_no_islands.to_csv(PANEL_PATH_OUT, index=False, encoding=\"utf-8-sig\")\n",
    "print(\"âœ… å·²ä¿å­˜å»å­¤å²›åçš„é¢æ¿:\", PANEL_PATH_OUT, \"| è¡Œæ•°:\", len(pdf_no_islands))\n",
    "\n",
    "gdf_no_islands = gdf_sub[~gdf_sub[\"__id__\"].isin(isles)].copy()\n",
    "cols = [c for c in gdf_no_islands.columns if c != \"__id__\"]\n",
    "gdf_no_islands = gdf_no_islands[cols]\n",
    "\n",
    "try:\n",
    "    if gdf_no_islands.crs and gdf_no_islands.crs.to_epsg() == 4326:\n",
    "        gdf_no_islands = gdf_no_islands.to_crs(3035)\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "gdf_no_islands.to_file(GEO_PATH_OUT, driver=\"GPKG\")\n",
    "print(\"âœ… å·²ä¿å­˜å»å­¤å²›åçš„ geo:\", GEO_PATH_OUT, \"| åŒºåŸŸæ•°:\", len(gdf_no_islands))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee6e4435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN(k=6) regions=195, components=1, min_deg=6, avg_deg=6.00\n",
      "âœ… saved: D:\\Dissertation\\dissertation\\data 2\\data\\Without UK and Germany\\Final\\moran\\weights_knn\\knn_full.png\n",
      "âœ… saved: D:\\Dissertation\\dissertation\\data 2\\data\\Without UK and Germany\\Final\\moran\\weights_knn\\knn_edges_only.png\n"
     ]
    }
   ],
   "source": [
    "# --- KNN æƒé‡ç½‘ç»œå›¾ ---\n",
    "from pathlib import Path\n",
    "import numpy as np, pandas as pd, geopandas as gpd, matplotlib.pyplot as plt\n",
    "from shapely.geometry import LineString\n",
    "from libpysal.weights import KNN\n",
    "import networkx as nx\n",
    "\n",
    "PANEL = r\"D:\\Dissertation\\dissertation\\data 2\\data\\Without UK and Germany\\Final\\moran\\filtered_by_islands\\panel_long_no_islands.csv\"\n",
    "GEO   = r\"D:\\Dissertation\\dissertation\\data 2\\data\\Without UK and Germany\\Final\\moran\\filtered_by_islands\\NUTS2_2021_no_islands.gpkg\"\n",
    "OUT   = Path(r\"D:\\Dissertation\\dissertation\\data 2\\data\\Without UK and Germany\\Final\\moran\\weights_knn\")\n",
    "OUT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "K = 6  # â† æƒ³æ›´å¯†å°±ç”¨ 10ï¼›æ›´ç¨€å°± 6\n",
    "\n",
    "def gid(gdf):\n",
    "    for c in [\"NUTS_ID\",\"nuts_id\",\"NUTS_ID_2021\",\"region\",\"code\",\"id\"]:\n",
    "        if c in gdf.columns: return c\n",
    "    return [c for c in gdf.columns if c != gdf.geometry.name][0]\n",
    "\n",
    "gdf = gpd.read_file(GEO)\n",
    "key = gid(gdf)\n",
    "gdf[\"region\"] = gdf[key].astype(\"string\").str.strip().str.upper()\n",
    "pdf = pd.read_csv(PANEL, encoding=\"utf-8-sig\")\n",
    "pdf[\"region\"] = pdf[\"region\"].astype(\"string\").str.strip().str.upper()\n",
    "\n",
    "g = gdf.merge(pdf[[\"region\"]].drop_duplicates(), on=\"region\", how=\"inner\").drop_duplicates(\"region\")\n",
    "if (not g.crs) or g.crs.to_epsg()==4326:\n",
    "    g = g.to_crs(3035)\n",
    "\n",
    "W = KNN.from_dataframe(g, k=K, use_index=True); W.transform = \"R\"\n",
    "\n",
    "# è¿æ¥æ€§è¯Šæ–­\n",
    "G = nx.Graph({i:{j:1 for j in W.neighbors[i]} for i in range(len(g))})\n",
    "comps = list(nx.connected_components(G))\n",
    "print(f\"KNN(k={K}) regions={len(g)}, components={len(comps)}, \"\n",
    "      f\"min_deg={min(len(W.neighbors[i]) for i in range(len(g)))}, \"\n",
    "      f\"avg_deg={np.mean([len(W.neighbors[i]) for i in range(len(g))]):.2f}\")\n",
    "\n",
    "# ç”»è¾¹\n",
    "cent = g.geometry.centroid\n",
    "xy = np.column_stack([cent.x.to_numpy(\"float64\"), cent.y.to_numpy(\"float64\")])\n",
    "lines=[]\n",
    "for i, nbrs in W.neighbors.items():\n",
    "    for j in nbrs:\n",
    "        if j<i: continue\n",
    "        lines.append(LineString([xy[i], xy[j]]))\n",
    "edges = gpd.GeoDataFrame(geometry=lines, crs=g.crs)\n",
    "\n",
    "# --- Full (åº•å›¾+è¾¹+ç‚¹)ï¼Œæ— ä»»ä½•æ–‡å­— ---\n",
    "fig, ax = plt.subplots(figsize=(9.5, 8))\n",
    "g.plot(ax=ax, color=\"#d9d9d9\", edgecolor=\"white\", linewidth=0.3)\n",
    "edges.plot(ax=ax, color=\"#7f9cf5\", linewidth=0.7, alpha=0.9)\n",
    "ax.scatter(cent.x, cent.y, s=7, zorder=3, color=\"crimson\")\n",
    "ax.set_axis_off()  # ä¸è¦åæ ‡è½´ä¸åˆ»åº¦\n",
    "fig.savefig(OUT / \"knn_full_no_text.png\", dpi=220,\n",
    "            bbox_inches=\"tight\", pad_inches=0)\n",
    "plt.close(fig)\n",
    "\n",
    "# --- Edges onlyï¼ˆä»…ç”»è¿çº¿ï¼‰ï¼Œæ— ä»»ä½•æ–‡å­— ---\n",
    "fig, ax = plt.subplots(figsize=(9.5, 8))\n",
    "edges.plot(ax=ax, color=\"#7f9cf5\", linewidth=0.8, alpha=0.95)\n",
    "ax.set_axis_off()\n",
    "fig.savefig(OUT / \"knn_edges_only_no_text.png\", dpi=220,\n",
    "            bbox_inches=\"tight\", pad_inches=0)\n",
    "plt.close(fig)\n",
    "\n",
    "print(\"âœ… saved:\", OUT/\"knn_full.png\")\n",
    "print(\"âœ… saved:\", OUT/\"knn_edges_only.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76b73697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Moran's I summary saved: D:\\Dissertation\\dissertation\\data 2\\data\\Without UK and Germany\\Final\\global_moran_knn6\\global_moran_summary_knn6_2014_2023.csv\n",
      "âœ… Timeseries saved: D:\\Dissertation\\dissertation\\data 2\\data\\Without UK and Germany\\Final\\global_moran_knn6\\employment_rate_moranI_timeseries_knn6_2014_2023.png\n",
      "âœ… Timeseries saved: D:\\Dissertation\\dissertation\\data 2\\data\\Without UK and Germany\\Final\\global_moran_knn6\\unemployment_rate_moranI_timeseries_knn6_2014_2023.png\n",
      "âœ… Timeseries saved: D:\\Dissertation\\dissertation\\data 2\\data\\Without UK and Germany\\Final\\global_moran_knn6\\log_gdp_pc_moranI_timeseries_knn6_2014_2023.png\n",
      "âœ… Timeseries saved: D:\\Dissertation\\dissertation\\data 2\\data\\Without UK and Germany\\Final\\global_moran_knn6\\vet_per_million_moranI_timeseries_knn6_2014_2023.png\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Global Moran's I with KNN (k=6), years 2014â€“2023, NUTS-2\n",
    "- è¾“å…¥ï¼španel_long_no_islands.csv + NUTS2_2021_no_islands.gpkg\n",
    "- æƒé‡ï¼šKNN k=6ï¼ˆrow-standardizedï¼‰\n",
    "- è¾“å‡ºï¼šæ±‡æ€»CSV + Moranæ•£ç‚¹å›¾(æ¯å¹´) + æ—¶é—´åºåˆ—å›¾(æ¯å˜é‡)\n",
    "\"\"\"\n",
    "\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from libpysal.weights import KNN, lag_spatial\n",
    "from esda.moran import Moran\n",
    "\n",
    "# ======= è·¯å¾„ =======\n",
    "PANEL_PATH = r\"D:\\Dissertation\\dissertation\\data 2\\data\\Without UK and Germany\\Final\\filtered_by_islands\\panel_long_no_islands.csv\"\n",
    "GEO_PATH   = r\"D:\\Dissertation\\dissertation\\data 2\\data\\Without UK and Germany\\Final\\filtered_by_islands\\NUTS2_2021_no_islands.gpkg\"\n",
    "OUT_DIR    = Path(r\"D:\\Dissertation\\dissertation\\data 2\\data\\Without UK and Germany\\Final\\global_moran_knn6\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ======= è®¾ç½® =======\n",
    "YEARS        = list(range(2014, 2024))\n",
    "VARS         = [\"employment_rate\", \"unemployment_rate\", \"log_gdp_pc\", \"vet_per_million\"]\n",
    "PERMUTATIONS = 999\n",
    "KNN_K        = 6\n",
    "MAKE_PLOTS   = True\n",
    "\n",
    "# ======= å°å·¥å…· =======\n",
    "def detect_geo_id(gdf: gpd.GeoDataFrame) -> str:\n",
    "    for c in [\"NUTS_ID\",\"nuts_id\",\"NUTS_ID_2021\",\"region\",\"code\",\"id\"]:\n",
    "        if c in gdf.columns: return c\n",
    "    return [c for c in gdf.columns if c != gdf.geometry.name][0]\n",
    "\n",
    "def zscore(x: np.ndarray) -> np.ndarray:\n",
    "    x = x.astype(float)\n",
    "    return (x - x.mean()) / x.std(ddof=0)\n",
    "\n",
    "# ======= è¯»æ•°æ® =======\n",
    "gdf = gpd.read_file(GEO_PATH)\n",
    "gid = detect_geo_id(gdf)\n",
    "gdf[\"region\"] = gdf[gid].astype(\"string\").str.strip().str.upper()\n",
    "if (not gdf.crs) or gdf.crs.to_epsg() == 4326:\n",
    "    gdf = gdf.to_crs(3035)\n",
    "\n",
    "pdf = pd.read_csv(PANEL_PATH, encoding=\"utf-8-sig\")\n",
    "pdf[\"region\"] = pdf[\"region\"].astype(\"string\").str.strip().str.upper()\n",
    "pdf[\"year\"]   = pd.to_numeric(pdf[\"year\"], errors=\"coerce\")\n",
    "for v in VARS:\n",
    "    if v in pdf.columns:\n",
    "        pdf[v] = pd.to_numeric(pdf[v], errors=\"coerce\")\n",
    "\n",
    "# ======= ä¸»å¾ªç¯ï¼šMoran's I =======\n",
    "rows = []\n",
    "for var in VARS:\n",
    "    (OUT_DIR / var).mkdir(parents=True, exist_ok=True)\n",
    "    for yr in YEARS:\n",
    "        d = pdf.loc[pdf[\"year\"] == yr, [\"region\", var]].dropna()\n",
    "        if d.empty: \n",
    "            continue\n",
    "        gg = gdf[[\"region\", \"geometry\"]].merge(d, on=\"region\", how=\"inner\").dropna(subset=[var])\n",
    "        if len(gg) < 5:\n",
    "            continue\n",
    "\n",
    "        # æƒé‡ï¼šKNN k=6ï¼ˆè¡Œæ ‡å‡†åŒ–ï¼‰\n",
    "        W = KNN.from_dataframe(gg, k=KNN_K, use_index=True)\n",
    "        W.transform = \"R\"\n",
    "\n",
    "        z = zscore(gg[var].to_numpy())\n",
    "        mi = Moran(z, W, permutations=PERMUTATIONS)\n",
    "\n",
    "        rows.append({\n",
    "            \"variable\": var, \"year\": yr, \"N\": int(len(gg)),\n",
    "            \"I\": float(mi.I), \"z_norm\": float(mi.z_norm), \"p_sim\": float(mi.p_sim),\n",
    "            \"weight\": f\"KNN(k={KNN_K})\", \"permutations\": PERMUTATIONS\n",
    "        })\n",
    "\n",
    "        # Moran æ•£ç‚¹å›¾\n",
    "        if MAKE_PLOTS:\n",
    "            wy = lag_spatial(W, z)\n",
    "            fig, ax = plt.subplots(figsize=(5.2, 4.2))\n",
    "            ax.scatter(z, wy, s=16, alpha=0.7)\n",
    "            ax.axhline(0, color=\"k\", lw=0.8, alpha=0.6)\n",
    "            ax.axvline(0, color=\"k\", lw=0.8, alpha=0.6)\n",
    "            xs = np.linspace(z.min(), z.max(), 100)\n",
    "            slope = np.cov(z, wy)[0,1] / np.var(z, ddof=0)  # æ‹Ÿåˆæ–œç‡â‰ˆIï¼ˆæ ‡å‡†åŒ–ä¸‹ï¼‰\n",
    "            ax.plot(xs, slope*xs, lw=1.2)\n",
    "            ax.set_xlabel(f\"Standardized {var}\")\n",
    "            ax.set_ylabel(f\"Spatial lag of {var}\")\n",
    "            ax.set_title(f\"{var} | {yr} | I={mi.I:.3f}, p={mi.p_sim:.3f}  (KNN k={KNN_K})\")\n",
    "            fig.tight_layout()\n",
    "            fig.savefig(OUT_DIR / var / f\"moran_scatter_{var}_{yr}.png\", dpi=180)\n",
    "            plt.close(fig)\n",
    "\n",
    "# ======= ä¿å­˜æ±‡æ€» & ç”»æ—¶é—´åºåˆ— =======\n",
    "res = pd.DataFrame(rows).sort_values([\"variable\",\"year\"])\n",
    "summary_csv = OUT_DIR / \"global_moran_summary_knn6_2014_2023.csv\"\n",
    "res.to_csv(summary_csv, index=False, encoding=\"utf-8-sig\")\n",
    "print(\"âœ… Moran's I summary saved:\", summary_csv)\n",
    "\n",
    "# æ—¶é—´åºåˆ—ï¼ˆæ¯å˜é‡ä¸€å¼ ï¼‰\n",
    "def star(p):\n",
    "    return \"***\" if p < 0.001 else (\"**\" if p < 0.01 else (\"*\" if p < 0.05 else \"\"))\n",
    "\n",
    "for var in VARS:\n",
    "    sub = res[res[\"variable\"] == var].sort_values(\"year\")\n",
    "    if sub.empty: \n",
    "        continue\n",
    "    fig, ax = plt.subplots(figsize=(7.5, 3.8))\n",
    "    ax.plot(sub[\"year\"], sub[\"I\"], marker=\"o\", lw=1.6)\n",
    "    for y, I, p in zip(sub[\"year\"], sub[\"I\"], sub[\"p_sim\"]):\n",
    "        s = star(p)\n",
    "        if s:\n",
    "            ax.text(y, I, s, ha=\"center\", va=\"bottom\", fontsize=10)\n",
    "    ax.axhline(0, color=\"k\", lw=0.8, alpha=0.6)\n",
    "    ax.set_title(f\"Global Moran's I over time (KNN k={KNN_K}): {var}\")\n",
    "    ax.set_xlabel(\"Year\"); ax.set_ylabel(\"Moran's I\")\n",
    "    ax.set_xticks(sorted(sub[\"year\"].unique()))\n",
    "    ax.grid(alpha=0.15)\n",
    "    fig.tight_layout()\n",
    "    out_png = OUT_DIR / f\"{var}_moranI_timeseries_knn{KNN_K}_2014_2023.png\"\n",
    "    fig.savefig(out_png, dpi=180)\n",
    "    plt.close(fig)\n",
    "    print(\"âœ… Timeseries saved:\", out_png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3e221a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… saved: D:\\Dissertation\\dissertation\\data 2\\data\\Without UK and Germany\\Final\\moran\\global_moran_knn6\\ten_years\\employment_rate_moran_scatter_grid_k6_2014_2023.png\n",
      "âœ… saved: D:\\Dissertation\\dissertation\\data 2\\data\\Without UK and Germany\\Final\\moran\\global_moran_knn6\\ten_years\\unemployment_rate_moran_scatter_grid_k6_2014_2023.png\n",
      "âœ… saved: D:\\Dissertation\\dissertation\\data 2\\data\\Without UK and Germany\\Final\\moran\\global_moran_knn6\\ten_years\\log_gdp_pc_moran_scatter_grid_k6_2014_2023.png\n",
      "âœ… saved: D:\\Dissertation\\dissertation\\data 2\\data\\Without UK and Germany\\Final\\moran\\global_moran_knn6\\ten_years\\vet_per_million_moran_scatter_grid_k6_2014_2023.png\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# Ten-year Moran scatterplot grid (2x5) with KNN(k=6), NUTS-2\n",
    "\n",
    "from pathlib import Path\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from libpysal.weights import KNN, lag_spatial\n",
    "\n",
    "# ========= è·¯å¾„ =========\n",
    "PANEL_PATH = r\"D:\\Dissertation\\dissertation\\data 2\\data\\Without UK and Germany\\Final\\moran\\filtered_by_islands\\panel_long_no_islands.csv\"\n",
    "GEO_PATH   = r\"D:\\Dissertation\\dissertation\\data 2\\data\\Without UK and Germany\\Final\\moran\\filtered_by_islands\\NUTS2_2021_no_islands.gpkg\"\n",
    "OUT_DIR    = Path(r\"D:\\Dissertation\\dissertation\\data 2\\data\\Without UK and Germany\\Final\\moran\\global_moran_knn6\\ten_years\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ========= è®¾ç½® =========\n",
    "YEARS  = list(range(2014, 2024))\n",
    "VARS   = [\"employment_rate\", \"unemployment_rate\", \"log_gdp_pc\", \"vet_per_million\"]\n",
    "KNN_K  = 6  # KNN é‚»å±…æ•°\n",
    "\n",
    "# ========= å°å·¥å…· =========\n",
    "def detect_geo_id(gdf: gpd.GeoDataFrame) -> str:\n",
    "    for c in [\"NUTS_ID\",\"nuts_id\",\"NUTS_ID_2021\",\"region\",\"code\",\"id\"]:\n",
    "        if c in gdf.columns:\n",
    "            return c\n",
    "    # å…œåº•ï¼šå–é geometry çš„ç¬¬ä¸€åˆ—\n",
    "    return [c for c in gdf.columns if c != gdf.geometry.name][0]\n",
    "\n",
    "def moran_grid_10y(panel_df, geo_df, var, years=range(2014, 2024),\n",
    "                   k=6, out_dir=OUT_DIR, include_suptitle=False):\n",
    "    \"\"\"åå¹´ Moran æ•£ç‚¹ 2Ã—5 é¢æ¿å›¾ï¼ˆæ¯å­å›¾æœ‰å¹´ä»½æ ‡é¢˜ï¼‰\"\"\"\n",
    "    cells, zmins, zmaxs = [], [], []\n",
    "    for yr in years:\n",
    "        d = panel_df.loc[panel_df[\"year\"] == yr, [\"region\", var]].dropna()\n",
    "        if d.empty:\n",
    "            continue\n",
    "        gg = geo_df[[\"region\",\"geometry\"]].merge(d, on=\"region\", how=\"inner\").dropna(subset=[var])\n",
    "        if len(gg) < 5:\n",
    "            continue\n",
    "\n",
    "        # æƒé‡ï¼šKNN(k) è¡Œæ ‡å‡†åŒ–\n",
    "        W = KNN.from_dataframe(gg, k=k, use_index=True)\n",
    "        W.transform = \"R\"\n",
    "\n",
    "        # æ ‡å‡†åŒ–å˜é‡ zï¼Œå¹¶è®¡ç®—ç©ºé—´æ»å wy\n",
    "        x = gg[var].to_numpy(float)\n",
    "        z  = (x - x.mean()) / x.std(ddof=0)\n",
    "        wy = lag_spatial(W, z)\n",
    "\n",
    "        cells.append((yr, z, wy))\n",
    "        zmins.append(z.min()); zmaxs.append(z.max())\n",
    "\n",
    "    if not cells:\n",
    "        return None\n",
    "\n",
    "    # ç»Ÿä¸€åæ ‡èŒƒå›´ã€å¸ƒå±€\n",
    "    zmin, zmax = min(zmins), max(zmaxs)\n",
    "    n = len(cells); ncols = 5; nrows = math.ceil(n / ncols)\n",
    "\n",
    "    fig, axes = plt.subplots(nrows, ncols, figsize=(ncols*2.6, nrows*2.4))\n",
    "    axes = np.array(axes).reshape(nrows, ncols)\n",
    "\n",
    "    for k_, (yr, z, wy) in enumerate(cells):\n",
    "        r, c = divmod(k_, ncols)\n",
    "        ax = axes[r, c]\n",
    "        ax.scatter(z, wy, s=12, alpha=0.75)\n",
    "        ax.axhline(0, lw=0.6, alpha=0.6); ax.axvline(0, lw=0.6, alpha=0.6)\n",
    "        xs = np.linspace(zmin, zmax, 120)\n",
    "        slope = np.cov(z, wy)[0,1] / np.var(z, ddof=0)  # æ–œç‡â‰ˆIï¼ˆæ ‡å‡†åŒ–ä¸‹ï¼‰\n",
    "        ax.plot(xs, slope*xs, lw=1.0)\n",
    "        ax.set_xlim(zmin, zmax)\n",
    "        ax.set_xticks([]); ax.set_yticks([])\n",
    "        ax.set_title(f\"{yr}\", fontsize=9)\n",
    "\n",
    "    # å…³æ‰å¤šä½™å­å›¾\n",
    "    for k_ in range(n, nrows*ncols):\n",
    "        r, c = divmod(k_, ncols)\n",
    "        axes[r, c].axis(\"off\")\n",
    "\n",
    "    if include_suptitle:\n",
    "        fig.suptitle(f\"Moran scatterplots â€” {var} (KNN k={k}, 2014â€“2023)\", y=0.98, fontsize=11)\n",
    "        fig.tight_layout(rect=[0,0,1,0.95])\n",
    "    else:\n",
    "        fig.tight_layout()\n",
    "\n",
    "    out_path = out_dir / f\"{var}_moran_scatter_grid_k{k}_2014_2023.png\"\n",
    "    fig.savefig(out_path, dpi=200, bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "    return out_path\n",
    "\n",
    "# ========= è¯»æ•°æ® =========\n",
    "gdf = gpd.read_file(GEO_PATH)\n",
    "gid = detect_geo_id(gdf)\n",
    "gdf[\"region\"] = gdf[gid].astype(\"string\").str.strip().str.upper()\n",
    "# æŠ•å½±ï¼šè‹¥æ˜¯ç»çº¬åº¦åˆ™è½¬ LAEA Europe\n",
    "try:\n",
    "    if (not gdf.crs) or gdf.crs.to_epsg() == 4326:\n",
    "        gdf = gdf.to_crs(3035)\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "pdf = pd.read_csv(PANEL_PATH, encoding=\"utf-8-sig\")\n",
    "pdf[\"region\"] = pdf[\"region\"].astype(\"string\").str.strip().str.upper()\n",
    "pdf[\"year\"]   = pd.to_numeric(pdf[\"year\"], errors=\"coerce\")\n",
    "for v in VARS:\n",
    "    if v in pdf.columns:\n",
    "        pdf[v] = pd.to_numeric(pdf[v], errors=\"coerce\")\n",
    "\n",
    "# ========= ç”Ÿæˆå¹¶ä¿å­˜ =========\n",
    "for var in VARS:\n",
    "    p = moran_grid_10y(pdf, gdf, var=var, years=YEARS, k=KNN_K,\n",
    "                       out_dir=OUT_DIR, include_suptitle=False)  # ä¸è¦æ€»æ ‡é¢˜\n",
    "    if p:\n",
    "        print(\"âœ… saved:\", p)\n",
    "    else:\n",
    "        print(f\"âš ï¸ no figure for {var} (insufficient data).\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4b5ec2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… employment_rate 2014: CSV: lisa_knn6_employment_rate_2014.csv | PNG: lisa_knn6_map_employment_rate_2014.png\n",
      "âœ… employment_rate 2015: CSV: lisa_knn6_employment_rate_2015.csv | PNG: lisa_knn6_map_employment_rate_2015.png\n",
      "âœ… employment_rate 2016: CSV: lisa_knn6_employment_rate_2016.csv | PNG: lisa_knn6_map_employment_rate_2016.png\n",
      "âœ… employment_rate 2017: CSV: lisa_knn6_employment_rate_2017.csv | PNG: lisa_knn6_map_employment_rate_2017.png\n",
      "âœ… employment_rate 2018: CSV: lisa_knn6_employment_rate_2018.csv | PNG: lisa_knn6_map_employment_rate_2018.png\n",
      "âœ… employment_rate 2019: CSV: lisa_knn6_employment_rate_2019.csv | PNG: lisa_knn6_map_employment_rate_2019.png\n",
      "âœ… employment_rate 2020: CSV: lisa_knn6_employment_rate_2020.csv | PNG: lisa_knn6_map_employment_rate_2020.png\n",
      "âœ… employment_rate 2021: CSV: lisa_knn6_employment_rate_2021.csv | PNG: lisa_knn6_map_employment_rate_2021.png\n",
      "âœ… employment_rate 2022: CSV: lisa_knn6_employment_rate_2022.csv | PNG: lisa_knn6_map_employment_rate_2022.png\n",
      "âœ… employment_rate 2023: CSV: lisa_knn6_employment_rate_2023.csv | PNG: lisa_knn6_map_employment_rate_2023.png\n",
      "âœ… unemployment_rate 2014: CSV: lisa_knn6_unemployment_rate_2014.csv | PNG: lisa_knn6_map_unemployment_rate_2014.png\n",
      "âœ… unemployment_rate 2015: CSV: lisa_knn6_unemployment_rate_2015.csv | PNG: lisa_knn6_map_unemployment_rate_2015.png\n",
      "âœ… unemployment_rate 2016: CSV: lisa_knn6_unemployment_rate_2016.csv | PNG: lisa_knn6_map_unemployment_rate_2016.png\n",
      "âœ… unemployment_rate 2017: CSV: lisa_knn6_unemployment_rate_2017.csv | PNG: lisa_knn6_map_unemployment_rate_2017.png\n",
      "âœ… unemployment_rate 2018: CSV: lisa_knn6_unemployment_rate_2018.csv | PNG: lisa_knn6_map_unemployment_rate_2018.png\n",
      "âœ… unemployment_rate 2019: CSV: lisa_knn6_unemployment_rate_2019.csv | PNG: lisa_knn6_map_unemployment_rate_2019.png\n",
      "âœ… unemployment_rate 2020: CSV: lisa_knn6_unemployment_rate_2020.csv | PNG: lisa_knn6_map_unemployment_rate_2020.png\n",
      "âœ… unemployment_rate 2021: CSV: lisa_knn6_unemployment_rate_2021.csv | PNG: lisa_knn6_map_unemployment_rate_2021.png\n",
      "âœ… unemployment_rate 2022: CSV: lisa_knn6_unemployment_rate_2022.csv | PNG: lisa_knn6_map_unemployment_rate_2022.png\n",
      "âœ… unemployment_rate 2023: CSV: lisa_knn6_unemployment_rate_2023.csv | PNG: lisa_knn6_map_unemployment_rate_2023.png\n",
      "âœ… log_gdp_pc 2014: CSV: lisa_knn6_log_gdp_pc_2014.csv | PNG: lisa_knn6_map_log_gdp_pc_2014.png\n",
      "âœ… log_gdp_pc 2015: CSV: lisa_knn6_log_gdp_pc_2015.csv | PNG: lisa_knn6_map_log_gdp_pc_2015.png\n",
      "âœ… log_gdp_pc 2016: CSV: lisa_knn6_log_gdp_pc_2016.csv | PNG: lisa_knn6_map_log_gdp_pc_2016.png\n",
      "âœ… log_gdp_pc 2017: CSV: lisa_knn6_log_gdp_pc_2017.csv | PNG: lisa_knn6_map_log_gdp_pc_2017.png\n",
      "âœ… log_gdp_pc 2018: CSV: lisa_knn6_log_gdp_pc_2018.csv | PNG: lisa_knn6_map_log_gdp_pc_2018.png\n",
      "âœ… log_gdp_pc 2019: CSV: lisa_knn6_log_gdp_pc_2019.csv | PNG: lisa_knn6_map_log_gdp_pc_2019.png\n",
      "âœ… log_gdp_pc 2020: CSV: lisa_knn6_log_gdp_pc_2020.csv | PNG: lisa_knn6_map_log_gdp_pc_2020.png\n",
      "âœ… log_gdp_pc 2021: CSV: lisa_knn6_log_gdp_pc_2021.csv | PNG: lisa_knn6_map_log_gdp_pc_2021.png\n",
      "âœ… log_gdp_pc 2022: CSV: lisa_knn6_log_gdp_pc_2022.csv | PNG: lisa_knn6_map_log_gdp_pc_2022.png\n",
      "âœ… log_gdp_pc 2023: CSV: lisa_knn6_log_gdp_pc_2023.csv | PNG: lisa_knn6_map_log_gdp_pc_2023.png\n",
      "âœ… vet_per_million 2014: CSV: lisa_knn6_vet_per_million_2014.csv | PNG: lisa_knn6_map_vet_per_million_2014.png\n",
      "âœ… vet_per_million 2015: CSV: lisa_knn6_vet_per_million_2015.csv | PNG: lisa_knn6_map_vet_per_million_2015.png\n",
      "âœ… vet_per_million 2016: CSV: lisa_knn6_vet_per_million_2016.csv | PNG: lisa_knn6_map_vet_per_million_2016.png\n",
      "âœ… vet_per_million 2017: CSV: lisa_knn6_vet_per_million_2017.csv | PNG: lisa_knn6_map_vet_per_million_2017.png\n",
      "âœ… vet_per_million 2018: CSV: lisa_knn6_vet_per_million_2018.csv | PNG: lisa_knn6_map_vet_per_million_2018.png\n",
      "âœ… vet_per_million 2019: CSV: lisa_knn6_vet_per_million_2019.csv | PNG: lisa_knn6_map_vet_per_million_2019.png\n",
      "âœ… vet_per_million 2020: CSV: lisa_knn6_vet_per_million_2020.csv | PNG: lisa_knn6_map_vet_per_million_2020.png\n",
      "âœ… vet_per_million 2021: CSV: lisa_knn6_vet_per_million_2021.csv | PNG: lisa_knn6_map_vet_per_million_2021.png\n",
      "âœ… vet_per_million 2022: CSV: lisa_knn6_vet_per_million_2022.csv | PNG: lisa_knn6_map_vet_per_million_2022.png\n",
      "âœ… vet_per_million 2023: CSV: lisa_knn6_vet_per_million_2023.csv | PNG: lisa_knn6_map_vet_per_million_2023.png\n",
      "âœ… Saved 10-year grid: D:\\Dissertation\\dissertation\\data 2\\data\\Without UK and Germany\\Final\\lisa_knn6\\employment_rate_moran_scatter_grid_knn6_2014_2023.png\n",
      "âœ… Saved 10-year grid: D:\\Dissertation\\dissertation\\data 2\\data\\Without UK and Germany\\Final\\lisa_knn6\\unemployment_rate_moran_scatter_grid_knn6_2014_2023.png\n",
      "âœ… Saved 10-year grid: D:\\Dissertation\\dissertation\\data 2\\data\\Without UK and Germany\\Final\\lisa_knn6\\log_gdp_pc_moran_scatter_grid_knn6_2014_2023.png\n",
      "âœ… Saved 10-year grid: D:\\Dissertation\\dissertation\\data 2\\data\\Without UK and Germany\\Final\\lisa_knn6\\vet_per_million_moran_scatter_grid_knn6_2014_2023.png\n",
      "\n",
      "ğŸ¯ All outputs â†’ D:\\Dissertation\\dissertation\\data 2\\data\\Without UK and Germany\\Final\\lisa_knn6\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "LISA (Local Moran's I) â€” KNN k=6, NUTS2, 2014â€“2023\n",
    "è¾“å‡ºï¼šæ¯å¹´Ã—æ¯å˜é‡ CSV + èšç±»åœ°å›¾ï¼›å¯é€‰åå¹´ 2Ã—5 é¢æ¿å›¾\n",
    "\"\"\"\n",
    "\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from libpysal.weights import KNN\n",
    "from esda.moran import Moran_Local\n",
    "\n",
    "# ========== è·¯å¾„ ==========\n",
    "PANEL_PATH = r\"D:\\Dissertation\\dissertation\\data 2\\data\\Without UK and Germany\\Final\\filtered_by_islands\\panel_long_no_islands.csv\"\n",
    "GEO_PATH   = r\"D:\\Dissertation\\dissertation\\data 2\\data\\Without UK and Germany\\Final\\filtered_by_islands\\NUTS2_2021_no_islands.gpkg\"\n",
    "OUT_DIR    = Path(r\"D:\\Dissertation\\dissertation\\data 2\\data\\Without UK and Germany\\Final\\lisa_knn6\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ========== è®¾ç½® ==========\n",
    "YEARS        = list(range(2014, 2024))\n",
    "VARS         = [\"employment_rate\", \"unemployment_rate\", \"log_gdp_pc\", \"vet_per_million\"]\n",
    "K            = 6\n",
    "ALPHA        = 0.05\n",
    "PERMUTATIONS = 999\n",
    "MAKE_GRID10  = True   # åå¹´ 2Ã—5 é¢æ¿å›¾å¼€å…³\n",
    "\n",
    "# ========== å·¥å…· ==========\n",
    "def detect_geo_id(gdf: gpd.GeoDataFrame) -> str:\n",
    "    for c in [\"NUTS_ID\",\"nuts_id\",\"NUTS_ID_2021\",\"region\",\"code\",\"id\"]:\n",
    "        if c in gdf.columns: return c\n",
    "    return [c for c in gdf.columns if c != gdf.geometry.name][0]\n",
    "\n",
    "def zscore(x: np.ndarray) -> np.ndarray:\n",
    "    x = x.astype(float)\n",
    "    return (x - x.mean()) / x.std(ddof=0)\n",
    "\n",
    "def lisa_cluster_labels(z, W, permutations=999, alpha=0.05):\n",
    "    ml = Moran_Local(z, W, permutations=permutations)\n",
    "    sig  = ml.p_sim < alpha\n",
    "    quad = ml.q  # 1 HH, 2 LH, 3 LL, 4 HL\n",
    "    labels = np.array([\"Not significant\"]*len(z), dtype=object)\n",
    "    labels[sig & (quad==1)] = \"High-High\"\n",
    "    labels[sig & (quad==2)] = \"Low-High\"\n",
    "    labels[sig & (quad==3)] = \"Low-Low\"\n",
    "    labels[sig & (quad==4)] = \"High-Low\"\n",
    "    return ml, sig, quad, labels\n",
    "\n",
    "# é¢œè‰² & é¡ºåº\n",
    "CLRS  = {\"High-High\":\"#d7191c\",\"Low-Low\":\"#2c7bb6\",\"High-Low\":\"#fdae61\",\"Low-High\":\"#abd9e9\",\"Not significant\":\"#e0e0e0\"}\n",
    "ORDER = [\"High-High\",\"Low-Low\",\"High-Low\",\"Low-High\",\"Not significant\"]\n",
    "\n",
    "# ========== è¯»æ•°æ® ==========\n",
    "gdf = gpd.read_file(GEO_PATH)\n",
    "gid = detect_geo_id(gdf)\n",
    "gdf[\"region\"] = gdf[gid].astype(\"string\").str.strip().str.upper()\n",
    "if (not gdf.crs) or gdf.crs.to_epsg()==4326:\n",
    "    gdf = gdf.to_crs(3035)\n",
    "\n",
    "pdf = pd.read_csv(PANEL_PATH, encoding=\"utf-8-sig\")\n",
    "pdf[\"region\"] = pdf[\"region\"].astype(\"string\").str.strip().str.upper()\n",
    "pdf[\"year\"]   = pd.to_numeric(pdf[\"year\"], errors=\"coerce\")\n",
    "for v in VARS:\n",
    "    if v in pdf.columns:\n",
    "        pdf[v] = pd.to_numeric(pdf[v], errors=\"coerce\")\n",
    "\n",
    "# ========== ä¸»å¾ªç¯ ==========\n",
    "for var in VARS:\n",
    "    vdir = OUT_DIR / var\n",
    "    vdir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for yr in YEARS:\n",
    "        d = pdf.loc[pdf[\"year\"]==yr, [\"region\", var]].dropna()\n",
    "        if d.empty: \n",
    "            continue\n",
    "\n",
    "        gg = gdf[[\"region\",\"geometry\"]].merge(d, on=\"region\", how=\"inner\").dropna(subset=[var])\n",
    "        if len(gg) < 5:\n",
    "            continue\n",
    "\n",
    "        # KNN k=6ï¼ˆè¡Œæ ‡å‡†åŒ–ï¼‰\n",
    "        W = KNN.from_dataframe(gg, k=K, use_index=True); W.transform = \"R\"\n",
    "\n",
    "        z = zscore(gg[var].to_numpy())\n",
    "        ml, sig, quad, labels = lisa_cluster_labels(z, W, permutations=PERMUTATIONS, alpha=ALPHA)\n",
    "\n",
    "        # ---- CSV ----\n",
    "        out_tbl = gg[[\"region\"]].copy()\n",
    "        out_tbl[\"Ii\"] = ml.Is\n",
    "        out_tbl[\"p_value\"] = ml.p_sim\n",
    "        out_tbl[\"quadrant\"] = quad\n",
    "        out_tbl[\"significant\"] = sig\n",
    "        out_tbl[\"cluster\"] = labels\n",
    "        csv_path = vdir / f\"lisa_knn6_{var}_{yr}.csv\"\n",
    "        out_tbl.to_csv(csv_path, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "        # ---- åœ°å›¾ ----\n",
    "        gg_plot = gg.copy()\n",
    "        gg_plot[\"cluster\"] = pd.Categorical(labels, categories=ORDER)\n",
    "        face = gg_plot[\"cluster\"].map(CLRS).fillna(\"#e0e0e0\")\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(7.6, 6.0))\n",
    "        gg_plot.plot(ax=ax, color=face, edgecolor=\"white\", linewidth=0.2)\n",
    "        ax.set_axis_off()\n",
    "        ax.set_title(f\"LISA â€” {var} ({yr})  Î±={ALPHA}, perms={PERMUTATIONS}\\nKNN (k={K}, row-standardized)\", fontsize=11)\n",
    "        import matplotlib.patches as mpatches\n",
    "        handles = [mpatches.Patch(color=CLRS[k], label=k) for k in ORDER]\n",
    "        ax.legend(handles=handles, title=\"Cluster\",\n",
    "                  loc=\"center left\", bbox_to_anchor=(1.02, 0.5),\n",
    "                  frameon=True, fancybox=True, framealpha=0.98)\n",
    "        fig.subplots_adjust(right=0.82)\n",
    "        png_path = vdir / f\"lisa_knn6_map_{var}_{yr}.png\"\n",
    "        fig.savefig(png_path, dpi=220, bbox_inches=\"tight\")\n",
    "        plt.close(fig)\n",
    "\n",
    "        print(f\"âœ… {var} {yr}: CSV: {csv_path.name} | PNG: {png_path.name}\")\n",
    "\n",
    "# ========== åå¹´ 2Ã—5 é¢æ¿ï¼ˆå¯é€‰ï¼‰ ==========\n",
    "if MAKE_GRID10:\n",
    "    import math\n",
    "    from libpysal.weights import lag_spatial\n",
    "\n",
    "    def moran_grid_knn(panel_df, geo_df, var, years, k=K, out_dir=OUT_DIR):\n",
    "        cells, zmins, zmaxs = [], [], []\n",
    "        for yr in years:\n",
    "            d = panel_df.loc[panel_df[\"year\"]==yr, [\"region\",var]].dropna()\n",
    "            if d.empty: continue\n",
    "            gg = geo_df[[\"region\",\"geometry\"]].merge(d, on=\"region\", how=\"inner\").dropna(subset=[var])\n",
    "            if len(gg)<5: continue\n",
    "            W = KNN.from_dataframe(gg, k=k, use_index=True); W.transform=\"R\"\n",
    "            z  = zscore(gg[var].to_numpy()); wy = lag_spatial(W, z)\n",
    "            cells.append((yr, z, wy)); zmins.append(z.min()); zmaxs.append(z.max())\n",
    "        if not cells: return None\n",
    "\n",
    "        zmin, zmax = min(zmins), max(zmaxs)\n",
    "        n, ncols = len(cells), 5\n",
    "        nrows = math.ceil(n/ncols)\n",
    "        fig, axes = plt.subplots(nrows, ncols, figsize=(ncols*2.6, nrows*2.4))\n",
    "        axes = np.array(axes).reshape(nrows, ncols)\n",
    "\n",
    "        for i,(yr,z,wy) in enumerate(cells):\n",
    "            r,c = divmod(i, ncols)\n",
    "            ax = axes[r,c]\n",
    "            ax.scatter(z, wy, s=12, alpha=0.7)\n",
    "            ax.axhline(0, color=\"k\", lw=0.6, alpha=0.6)\n",
    "            ax.axvline(0, color=\"k\", lw=0.6, alpha=0.6)\n",
    "            xs = np.linspace(zmin, zmax, 100)\n",
    "            slope = np.cov(z, wy)[0,1] / np.var(z, ddof=0)\n",
    "            ax.plot(xs, slope*xs, lw=1.0)\n",
    "            ax.set_xlim(zmin, zmax)\n",
    "            ax.set_xticks([]); ax.set_yticks([])\n",
    "            ax.set_title(f\"{yr}\", fontsize=9)\n",
    "\n",
    "        for j in range(n, nrows*ncols):\n",
    "            r,c = divmod(j, ncols); axes[r,c].axis(\"off\")\n",
    "\n",
    "        fig.suptitle(f\"Moran scatterplots â€” {var} (KNN k={k}, 2014â€“2023)\", y=0.98, fontsize=11)\n",
    "        fig.tight_layout(rect=[0,0,1,0.95])\n",
    "        out_path = out_dir / f\"{var}_moran_scatter_grid_knn{k}_2014_2023.png\"\n",
    "        fig.savefig(out_path, dpi=200); plt.close(fig)\n",
    "        return out_path\n",
    "\n",
    "    for var in VARS:\n",
    "        pth = moran_grid_knn(pdf, gdf, var, YEARS, k=K, out_dir=OUT_DIR)\n",
    "        if pth: print(\"âœ… Saved 10-year grid:\", pth)\n",
    "\n",
    "print(\"\\nğŸ¯ All outputs â†’\", OUT_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "144b1e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… employment_rate 2014: CSV: lisa_knn6_employment_rate_2014.csv | PNG: lisa_knn6_map_employment_rate_2014.png\n",
      "âœ… employment_rate 2015: CSV: lisa_knn6_employment_rate_2015.csv | PNG: lisa_knn6_map_employment_rate_2015.png\n",
      "âœ… employment_rate 2016: CSV: lisa_knn6_employment_rate_2016.csv | PNG: lisa_knn6_map_employment_rate_2016.png\n",
      "âœ… employment_rate 2017: CSV: lisa_knn6_employment_rate_2017.csv | PNG: lisa_knn6_map_employment_rate_2017.png\n",
      "âœ… employment_rate 2018: CSV: lisa_knn6_employment_rate_2018.csv | PNG: lisa_knn6_map_employment_rate_2018.png\n",
      "âœ… employment_rate 2019: CSV: lisa_knn6_employment_rate_2019.csv | PNG: lisa_knn6_map_employment_rate_2019.png\n",
      "âœ… employment_rate 2020: CSV: lisa_knn6_employment_rate_2020.csv | PNG: lisa_knn6_map_employment_rate_2020.png\n",
      "âœ… employment_rate 2021: CSV: lisa_knn6_employment_rate_2021.csv | PNG: lisa_knn6_map_employment_rate_2021.png\n",
      "âœ… employment_rate 2022: CSV: lisa_knn6_employment_rate_2022.csv | PNG: lisa_knn6_map_employment_rate_2022.png\n",
      "âœ… employment_rate 2023: CSV: lisa_knn6_employment_rate_2023.csv | PNG: lisa_knn6_map_employment_rate_2023.png\n",
      "ğŸ§© Saved 10-year LISA grid for employment_rate: D:\\Dissertation\\dissertation\\data 2\\data\\Without UK and Germany\\Final\\moran\\lisa_10\\employment_rate_LISA_grid_2014_2023_knn6.png\n",
      "âœ… unemployment_rate 2014: CSV: lisa_knn6_unemployment_rate_2014.csv | PNG: lisa_knn6_map_unemployment_rate_2014.png\n",
      "âœ… unemployment_rate 2015: CSV: lisa_knn6_unemployment_rate_2015.csv | PNG: lisa_knn6_map_unemployment_rate_2015.png\n",
      "âœ… unemployment_rate 2016: CSV: lisa_knn6_unemployment_rate_2016.csv | PNG: lisa_knn6_map_unemployment_rate_2016.png\n",
      "âœ… unemployment_rate 2017: CSV: lisa_knn6_unemployment_rate_2017.csv | PNG: lisa_knn6_map_unemployment_rate_2017.png\n",
      "âœ… unemployment_rate 2018: CSV: lisa_knn6_unemployment_rate_2018.csv | PNG: lisa_knn6_map_unemployment_rate_2018.png\n",
      "âœ… unemployment_rate 2019: CSV: lisa_knn6_unemployment_rate_2019.csv | PNG: lisa_knn6_map_unemployment_rate_2019.png\n",
      "âœ… unemployment_rate 2020: CSV: lisa_knn6_unemployment_rate_2020.csv | PNG: lisa_knn6_map_unemployment_rate_2020.png\n",
      "âœ… unemployment_rate 2021: CSV: lisa_knn6_unemployment_rate_2021.csv | PNG: lisa_knn6_map_unemployment_rate_2021.png\n",
      "âœ… unemployment_rate 2022: CSV: lisa_knn6_unemployment_rate_2022.csv | PNG: lisa_knn6_map_unemployment_rate_2022.png\n",
      "âœ… unemployment_rate 2023: CSV: lisa_knn6_unemployment_rate_2023.csv | PNG: lisa_knn6_map_unemployment_rate_2023.png\n",
      "ğŸ§© Saved 10-year LISA grid for unemployment_rate: D:\\Dissertation\\dissertation\\data 2\\data\\Without UK and Germany\\Final\\moran\\lisa_10\\unemployment_rate_LISA_grid_2014_2023_knn6.png\n",
      "âœ… log_gdp_pc 2014: CSV: lisa_knn6_log_gdp_pc_2014.csv | PNG: lisa_knn6_map_log_gdp_pc_2014.png\n",
      "âœ… log_gdp_pc 2015: CSV: lisa_knn6_log_gdp_pc_2015.csv | PNG: lisa_knn6_map_log_gdp_pc_2015.png\n",
      "âœ… log_gdp_pc 2016: CSV: lisa_knn6_log_gdp_pc_2016.csv | PNG: lisa_knn6_map_log_gdp_pc_2016.png\n",
      "âœ… log_gdp_pc 2017: CSV: lisa_knn6_log_gdp_pc_2017.csv | PNG: lisa_knn6_map_log_gdp_pc_2017.png\n",
      "âœ… log_gdp_pc 2018: CSV: lisa_knn6_log_gdp_pc_2018.csv | PNG: lisa_knn6_map_log_gdp_pc_2018.png\n",
      "âœ… log_gdp_pc 2019: CSV: lisa_knn6_log_gdp_pc_2019.csv | PNG: lisa_knn6_map_log_gdp_pc_2019.png\n",
      "âœ… log_gdp_pc 2020: CSV: lisa_knn6_log_gdp_pc_2020.csv | PNG: lisa_knn6_map_log_gdp_pc_2020.png\n",
      "âœ… log_gdp_pc 2021: CSV: lisa_knn6_log_gdp_pc_2021.csv | PNG: lisa_knn6_map_log_gdp_pc_2021.png\n",
      "âœ… log_gdp_pc 2022: CSV: lisa_knn6_log_gdp_pc_2022.csv | PNG: lisa_knn6_map_log_gdp_pc_2022.png\n",
      "âœ… log_gdp_pc 2023: CSV: lisa_knn6_log_gdp_pc_2023.csv | PNG: lisa_knn6_map_log_gdp_pc_2023.png\n",
      "ğŸ§© Saved 10-year LISA grid for log_gdp_pc: D:\\Dissertation\\dissertation\\data 2\\data\\Without UK and Germany\\Final\\moran\\lisa_10\\log_gdp_pc_LISA_grid_2014_2023_knn6.png\n",
      "âœ… vet_per_million 2014: CSV: lisa_knn6_vet_per_million_2014.csv | PNG: lisa_knn6_map_vet_per_million_2014.png\n",
      "âœ… vet_per_million 2015: CSV: lisa_knn6_vet_per_million_2015.csv | PNG: lisa_knn6_map_vet_per_million_2015.png\n",
      "âœ… vet_per_million 2016: CSV: lisa_knn6_vet_per_million_2016.csv | PNG: lisa_knn6_map_vet_per_million_2016.png\n",
      "âœ… vet_per_million 2017: CSV: lisa_knn6_vet_per_million_2017.csv | PNG: lisa_knn6_map_vet_per_million_2017.png\n",
      "âœ… vet_per_million 2018: CSV: lisa_knn6_vet_per_million_2018.csv | PNG: lisa_knn6_map_vet_per_million_2018.png\n",
      "âœ… vet_per_million 2019: CSV: lisa_knn6_vet_per_million_2019.csv | PNG: lisa_knn6_map_vet_per_million_2019.png\n",
      "âœ… vet_per_million 2020: CSV: lisa_knn6_vet_per_million_2020.csv | PNG: lisa_knn6_map_vet_per_million_2020.png\n",
      "âœ… vet_per_million 2021: CSV: lisa_knn6_vet_per_million_2021.csv | PNG: lisa_knn6_map_vet_per_million_2021.png\n",
      "âœ… vet_per_million 2022: CSV: lisa_knn6_vet_per_million_2022.csv | PNG: lisa_knn6_map_vet_per_million_2022.png\n",
      "âœ… vet_per_million 2023: CSV: lisa_knn6_vet_per_million_2023.csv | PNG: lisa_knn6_map_vet_per_million_2023.png\n",
      "ğŸ§© Saved 10-year LISA grid for vet_per_million: D:\\Dissertation\\dissertation\\data 2\\data\\Without UK and Germany\\Final\\moran\\lisa_10\\vet_per_million_LISA_grid_2014_2023_knn6.png\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "LISA (Local Moran's I) â€” KNN k=6, NUTS2, 2014â€“2023\n",
    "è¾“å‡ºï¼šæ¯å¹´Ã—æ¯å˜é‡ CSV + èšç±»åœ°å›¾ï¼›å¹¶æŠŠæ¯å˜é‡ 10 å¹´å›¾æ•´åˆæˆ 1 å¼  2Ã—5 é¢æ¿å›¾\n",
    "\"\"\"\n",
    "\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from libpysal.weights import KNN\n",
    "from esda.moran import Moran_Local\n",
    "\n",
    "# ========== è·¯å¾„ ==========\n",
    "PANEL_PATH = r\"D:\\Dissertation\\dissertation\\data 2\\data\\Without UK and Germany\\Final\\moran\\filtered_by_islands\\panel_long_no_islands.csv\"\n",
    "GEO_PATH   = r\"D:\\Dissertation\\dissertation\\data 2\\data\\Without UK and Germany\\Final\\moran\\filtered_by_islands\\NUTS2_2021_no_islands.gpkg\"\n",
    "OUT_DIR    = Path(r\"D:\\Dissertation\\dissertation\\data 2\\data\\Without UK and Germany\\Final\\moran\\lisa_10\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ========== è®¾ç½® ==========\n",
    "YEARS        = list(range(2014, 2024))\n",
    "VARS         = [\"employment_rate\", \"unemployment_rate\", \"log_gdp_pc\", \"vet_per_million\"]\n",
    "K            = 6\n",
    "ALPHA        = 0.05\n",
    "PERMUTATIONS = 999\n",
    "\n",
    "# ========== å·¥å…· ==========\n",
    "def detect_geo_id(gdf: gpd.GeoDataFrame) -> str:\n",
    "    for c in [\"NUTS_ID\",\"nuts_id\",\"NUTS_ID_2021\",\"region\",\"code\",\"id\"]:\n",
    "        if c in gdf.columns: return c\n",
    "    return [c for c in gdf.columns if c != gdf.geometry.name][0]\n",
    "\n",
    "def zscore(x: np.ndarray) -> np.ndarray:\n",
    "    x = x.astype(float)\n",
    "    return (x - x.mean()) / x.std(ddof=0)\n",
    "\n",
    "def lisa_cluster_labels(z, W, permutations=999, alpha=0.05):\n",
    "    ml = Moran_Local(z, W, permutations=permutations)\n",
    "    sig  = ml.p_sim < alpha\n",
    "    quad = ml.q  # 1 HH, 2 LH, 3 LL, 4 HL\n",
    "    labels = np.array([\"Not significant\"]*len(z), dtype=object)\n",
    "    labels[sig & (quad==1)] = \"High-High\"\n",
    "    labels[sig & (quad==2)] = \"Low-High\"\n",
    "    labels[sig & (quad==3)] = \"Low-Low\"\n",
    "    labels[sig & (quad==4)] = \"High-Low\"\n",
    "    return ml, sig, quad, labels\n",
    "\n",
    "# é¢œè‰² & é¡ºåº\n",
    "CLRS  = {\"High-High\":\"#d7191c\",\"Low-Low\":\"#2c7bb6\",\"High-Low\":\"#fdae61\",\"Low-High\":\"#abd9e9\",\"Not significant\":\"#e0e0e0\"}\n",
    "ORDER = [\"High-High\",\"Low-Low\",\"High-Low\",\"Low-High\",\"Not significant\"]\n",
    "\n",
    "# ========== è¯»æ•°æ® ==========\n",
    "gdf = gpd.read_file(GEO_PATH)\n",
    "gid = detect_geo_id(gdf)\n",
    "gdf[\"region\"] = gdf[gid].astype(\"string\").str.strip().str.upper()\n",
    "if (not gdf.crs) or gdf.crs.to_epsg()==4326:\n",
    "    gdf = gdf.to_crs(3035)\n",
    "\n",
    "pdf = pd.read_csv(PANEL_PATH, encoding=\"utf-8-sig\")\n",
    "pdf[\"region\"] = pdf[\"region\"].astype(\"string\").str.strip().str.upper()\n",
    "pdf[\"year\"]   = pd.to_numeric(pdf[\"year\"], errors=\"coerce\")\n",
    "for v in VARS:\n",
    "    if v in pdf.columns:\n",
    "        pdf[v] = pd.to_numeric(pdf[v], errors=\"coerce\")\n",
    "\n",
    "# é¢„å…ˆè®°å½•æ•´å¹…åœ°å›¾èŒƒå›´ï¼Œä¿è¯é¢æ¿å­å›¾èŒƒå›´ä¸€è‡´\n",
    "xmin, ymin, xmax, ymax = gdf.total_bounds\n",
    "\n",
    "# ========== ä¸»å¾ªç¯ ==========\n",
    "for var in VARS:\n",
    "    vdir = OUT_DIR / var\n",
    "    vdir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # ä¸ºé¢æ¿å›¾ç¼“å­˜æ¯å¹´çš„â€œæ¶‚è‰²åâ€GeoDataFrameï¼ˆåªå­˜ cluster åˆ—å³å¯ï¼‰\n",
    "    yearly_maps = []   # list of (year, gg_plot_with_cluster)\n",
    "\n",
    "    for yr in YEARS:\n",
    "        d = pdf.loc[pdf[\"year\"]==yr, [\"region\", var]].dropna()\n",
    "        if d.empty:\n",
    "            continue\n",
    "\n",
    "        gg = gdf[[\"region\",\"geometry\"]].merge(d, on=\"region\", how=\"inner\").dropna(subset=[var])\n",
    "        if len(gg) < 5:\n",
    "            continue\n",
    "\n",
    "        # KNN k=6ï¼ˆè¡Œæ ‡å‡†åŒ–ï¼‰\n",
    "        W = KNN.from_dataframe(gg, k=K, use_index=True); W.transform = \"R\"\n",
    "\n",
    "        z = zscore(gg[var].to_numpy())\n",
    "        ml, sig, quad, labels = lisa_cluster_labels(z, W, permutations=PERMUTATIONS, alpha=ALPHA)\n",
    "\n",
    "        # ---- CSV ----\n",
    "        out_tbl = gg[[\"region\"]].copy()\n",
    "        out_tbl[\"Ii\"] = ml.Is\n",
    "        out_tbl[\"p_value\"] = ml.p_sim\n",
    "        out_tbl[\"quadrant\"] = quad\n",
    "        out_tbl[\"significant\"] = sig\n",
    "        out_tbl[\"cluster\"] = labels\n",
    "        csv_path = vdir / f\"lisa_knn6_{var}_{yr}.csv\"\n",
    "        out_tbl.to_csv(csv_path, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "        # ---- å•å¹´åœ°å›¾ ----\n",
    "        gg_plot = gg.copy()\n",
    "        gg_plot[\"cluster\"] = pd.Categorical(labels, categories=ORDER)\n",
    "        face = gg_plot[\"cluster\"].map(CLRS).fillna(\"#e0e0e0\")\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(7.6, 6.0))\n",
    "        gg_plot.plot(ax=ax, color=face, edgecolor=\"white\", linewidth=0.2)\n",
    "        ax.set_xlim(xmin, xmax); ax.set_ylim(ymin, ymax)\n",
    "        ax.set_axis_off()\n",
    "        ax.set_title(f\"LISA â€” {var} ({yr})  Î±={ALPHA}, perms={PERMUTATIONS}\\nKNN (k={K}, row-standardized)\", fontsize=11)\n",
    "        import matplotlib.patches as mpatches\n",
    "        handles = [mpatches.Patch(color=CLRS[k], label=k) for k in ORDER]\n",
    "        ax.legend(handles=handles, title=\"Cluster\",\n",
    "                  loc=\"center left\", bbox_to_anchor=(1.02, 0.5),\n",
    "                  frameon=True, fancybox=True, framealpha=0.98)\n",
    "        fig.subplots_adjust(right=0.82)\n",
    "        png_path = vdir / f\"lisa_knn6_map_{var}_{yr}.png\"\n",
    "        fig.savefig(png_path, dpi=220, bbox_inches=\"tight\")\n",
    "        plt.close(fig)\n",
    "\n",
    "        # â€”â€” ä¸ºé¢æ¿å›¾ç¼“å­˜ï¼ˆåªå­˜ cluster åˆ†ç±»å³å¯ï¼‰â€”â€”\n",
    "        cache = gg[[\"region\",\"geometry\"]].copy()\n",
    "        cache[\"cluster\"] = gg_plot[\"cluster\"].astype(str).values\n",
    "        yearly_maps.append((yr, cache))\n",
    "\n",
    "        print(f\"âœ… {var} {yr}: CSV: {csv_path.name} | PNG: {png_path.name}\")\n",
    "\n",
    "    # ========== æ¯å˜é‡åå¹´åˆä¸€ï¼ˆ2Ã—5ï¼‰é¢æ¿å›¾ ==========\n",
    "    if len(yearly_maps) > 0:\n",
    "        # æŒ‰å¹´ä»½æ’åº\n",
    "        yearly_maps = sorted(yearly_maps, key=lambda x: x[0])\n",
    "\n",
    "        n = len(yearly_maps)\n",
    "        ncols = 5\n",
    "        nrows = int(np.ceil(n / ncols))\n",
    "\n",
    "        fig, axes = plt.subplots(nrows, ncols, figsize=(ncols*3.2, nrows*3.0))\n",
    "        axes = np.array(axes).reshape(nrows, ncols)\n",
    "\n",
    "        for i, (yr, cache) in enumerate(yearly_maps):\n",
    "            r, c = divmod(i, ncols)\n",
    "            ax = axes[r, c]\n",
    "            # é¢œè‰²æ˜ å°„\n",
    "            face = cache[\"cluster\"].map(CLRS).fillna(\"#e0e0e0\")\n",
    "            cache.plot(ax=ax, color=face, edgecolor=\"white\", linewidth=0.18)\n",
    "            ax.set_xlim(xmin, xmax); ax.set_ylim(ymin, ymax)\n",
    "            ax.set_title(str(yr), fontsize=10)\n",
    "            ax.set_axis_off()\n",
    "\n",
    "        # å¤šä½™å­å›¾å…³æ‰\n",
    "        for k in range(n, nrows*ncols):\n",
    "            r, c = divmod(k, ncols)\n",
    "            axes[r, c].axis(\"off\")\n",
    "\n",
    "        # æ€»æ ‡é¢˜ & å›¾ä¾‹ï¼ˆæ•´å¼ å›¾åªæ”¾ä¸€ä¸ªå›¾ä¾‹ï¼‰\n",
    "        import matplotlib.patches as mpatches\n",
    "        handles = [mpatches.Patch(color=CLRS[k], label=k) for k in ORDER]\n",
    "        fig.suptitle(f\"LISA clusters â€” {var} (KNN k={K}, Î±={ALPHA}, perms={PERMUTATIONS})  |  2014â€“2023\",\n",
    "                     fontsize=12, y=0.98)\n",
    "        fig.legend(handles=handles, title=\"Cluster\",\n",
    "                   loc=\"center left\", bbox_to_anchor=(1.02, 0.5),\n",
    "                   frameon=True, fancybox=True, framealpha=0.98)\n",
    "\n",
    "        fig.tight_layout(rect=[0,0,0.98,0.96])\n",
    "        grid_png = OUT_DIR / f\"{var}_LISA_grid_2014_2023_knn{K}.png\"\n",
    "        fig.savefig(grid_png, dpi=220, bbox_inches=\"tight\")\n",
    "        plt.close(fig)\n",
    "        print(f\"ğŸ§© Saved 10-year LISA grid for {var}: {grid_png}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05420243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… employment_rate 2014: CSV + PNG done.\n",
      "âœ… employment_rate 2015: CSV + PNG done.\n",
      "âœ… employment_rate 2016: CSV + PNG done.\n",
      "âœ… employment_rate 2017: CSV + PNG done.\n",
      "âœ… employment_rate 2018: CSV + PNG done.\n",
      "âœ… employment_rate 2019: CSV + PNG done.\n",
      "âœ… employment_rate 2020: CSV + PNG done.\n",
      "âœ… employment_rate 2021: CSV + PNG done.\n",
      "âœ… employment_rate 2022: CSV + PNG done.\n",
      "âœ… employment_rate 2023: CSV + PNG done.\n",
      "ğŸ“Œ Saved MAIN (1x3) LISA figure for employment_rate: D:\\Dissertation\\dissertation\\data 2\\data\\Without UK and Germany\\Final\\moran\\lisa_A\\employment_rate_LISA_rep_years_2014-2019-2023_knn6.png\n",
      "ğŸ§© Saved APPENDIX (2x5) LISA grid for employment_rate: D:\\Dissertation\\dissertation\\data 2\\data\\Without UK and Germany\\Final\\moran\\lisa_A\\employment_rate_LISA_grid_2014_2023_knn6.png\n",
      "âœ… unemployment_rate 2014: CSV + PNG done.\n",
      "âœ… unemployment_rate 2015: CSV + PNG done.\n",
      "âœ… unemployment_rate 2016: CSV + PNG done.\n",
      "âœ… unemployment_rate 2017: CSV + PNG done.\n",
      "âœ… unemployment_rate 2018: CSV + PNG done.\n",
      "âœ… unemployment_rate 2019: CSV + PNG done.\n",
      "âœ… unemployment_rate 2020: CSV + PNG done.\n",
      "âœ… unemployment_rate 2021: CSV + PNG done.\n",
      "âœ… unemployment_rate 2022: CSV + PNG done.\n",
      "âœ… unemployment_rate 2023: CSV + PNG done.\n",
      "ğŸ“Œ Saved MAIN (1x3) LISA figure for unemployment_rate: D:\\Dissertation\\dissertation\\data 2\\data\\Without UK and Germany\\Final\\moran\\lisa_A\\unemployment_rate_LISA_rep_years_2014-2019-2023_knn6.png\n",
      "ğŸ§© Saved APPENDIX (2x5) LISA grid for unemployment_rate: D:\\Dissertation\\dissertation\\data 2\\data\\Without UK and Germany\\Final\\moran\\lisa_A\\unemployment_rate_LISA_grid_2014_2023_knn6.png\n",
      "âœ… log_gdp_pc 2014: CSV + PNG done.\n",
      "âœ… log_gdp_pc 2015: CSV + PNG done.\n",
      "âœ… log_gdp_pc 2016: CSV + PNG done.\n",
      "âœ… log_gdp_pc 2017: CSV + PNG done.\n",
      "âœ… log_gdp_pc 2018: CSV + PNG done.\n",
      "âœ… log_gdp_pc 2019: CSV + PNG done.\n",
      "âœ… log_gdp_pc 2020: CSV + PNG done.\n",
      "âœ… log_gdp_pc 2021: CSV + PNG done.\n",
      "âœ… log_gdp_pc 2022: CSV + PNG done.\n",
      "âœ… log_gdp_pc 2023: CSV + PNG done.\n",
      "ğŸ“Œ Saved MAIN (1x3) LISA figure for log_gdp_pc: D:\\Dissertation\\dissertation\\data 2\\data\\Without UK and Germany\\Final\\moran\\lisa_A\\log_gdp_pc_LISA_rep_years_2014-2019-2023_knn6.png\n",
      "ğŸ§© Saved APPENDIX (2x5) LISA grid for log_gdp_pc: D:\\Dissertation\\dissertation\\data 2\\data\\Without UK and Germany\\Final\\moran\\lisa_A\\log_gdp_pc_LISA_grid_2014_2023_knn6.png\n",
      "âœ… vet_per_million 2014: CSV + PNG done.\n",
      "âœ… vet_per_million 2015: CSV + PNG done.\n",
      "âœ… vet_per_million 2016: CSV + PNG done.\n",
      "âœ… vet_per_million 2017: CSV + PNG done.\n",
      "âœ… vet_per_million 2018: CSV + PNG done.\n",
      "âœ… vet_per_million 2019: CSV + PNG done.\n",
      "âœ… vet_per_million 2020: CSV + PNG done.\n",
      "âœ… vet_per_million 2021: CSV + PNG done.\n",
      "âœ… vet_per_million 2022: CSV + PNG done.\n",
      "âœ… vet_per_million 2023: CSV + PNG done.\n",
      "ğŸ“Œ Saved MAIN (1x3) LISA figure for vet_per_million: D:\\Dissertation\\dissertation\\data 2\\data\\Without UK and Germany\\Final\\moran\\lisa_A\\vet_per_million_LISA_rep_years_2014-2019-2023_knn6.png\n",
      "ğŸ§© Saved APPENDIX (2x5) LISA grid for vet_per_million: D:\\Dissertation\\dissertation\\data 2\\data\\Without UK and Germany\\Final\\moran\\lisa_A\\vet_per_million_LISA_grid_2014_2023_knn6.png\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "LISA (Local Moran's I) â€” KNN k=6, NUTS2, 2014â€“2023\n",
    "æ–¹æ¡ˆAï¼š\n",
    "- æ­£æ–‡ï¼šæ¯å˜é‡ 3 ä¸ªä»£è¡¨å¹´ä»½ï¼ˆ2014, 2019, 2023ï¼‰ â†’ 1Ã—3 é¢æ¿å›¾ï¼ˆå¤§ã€æ¸…æ™°ã€å…±ç”¨å›¾ä¾‹ã€æ— æ€»æ ‡é¢˜ï¼‰\n",
    "- é™„å½•ï¼ˆå¯é€‰ï¼‰ï¼šæ¯å˜é‡ 10 å¹´ â†’ 2Ã—5 é¢æ¿å›¾\n",
    "- é€å¹´ï¼šCSV + å•å¹´åœ°å›¾ï¼ˆä¿ç•™ï¼‰\n",
    "\"\"\"\n",
    "\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from libpysal.weights import KNN\n",
    "from esda.moran import Moran_Local\n",
    "\n",
    "# ========== è·¯å¾„ ==========\n",
    "PANEL_PATH = r\"D:\\Dissertation\\dissertation\\data 2\\data\\Without UK and Germany\\Final\\moran\\filtered_by_islands\\panel_long_no_islands.csv\"\n",
    "GEO_PATH   = r\"D:\\Dissertation\\dissertation\\data 2\\data\\Without UK and Germany\\Final\\moran\\filtered_by_islands\\NUTS2_2021_no_islands.gpkg\"\n",
    "OUT_DIR    = Path(r\"D:\\Dissertation\\dissertation\\data 2\\data\\Without UK and Germany\\Final\\moran\\lisa_A\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ========== è®¾ç½® ==========\n",
    "YEARS          = list(range(2014, 2024))\n",
    "REP_YEARS      = [2014, 2019, 2023]     # æ­£æ–‡ä»£è¡¨å¹´ä»½ï¼ˆå¯æ”¹ï¼‰\n",
    "VARS           = [\"employment_rate\", \"unemployment_rate\", \"log_gdp_pc\", \"vet_per_million\"]\n",
    "K              = 6\n",
    "ALPHA          = 0.05\n",
    "PERMUTATIONS   = 999\n",
    "MAKE_APPENDIX  = True                   # æ˜¯å¦é¢å¤–è¾“å‡º 2Ã—5 å…¨æ—¶æœŸé¢æ¿\n",
    "\n",
    "# ========== å·¥å…· ==========\n",
    "def detect_geo_id(gdf: gpd.GeoDataFrame) -> str:\n",
    "    for c in [\"NUTS_ID\",\"nuts_id\",\"NUTS_ID_2021\",\"region\",\"code\",\"id\"]:\n",
    "        if c in gdf.columns: return c\n",
    "    return [c for c in gdf.columns if c != gdf.geometry.name][0]\n",
    "\n",
    "def zscore(x: np.ndarray) -> np.ndarray:\n",
    "    x = x.astype(float)\n",
    "    return (x - x.mean()) / x.std(ddof=0)\n",
    "\n",
    "def lisa_cluster_labels(z, W, permutations=999, alpha=0.05):\n",
    "    ml = Moran_Local(z, W, permutations=permutations)\n",
    "    sig  = ml.p_sim < alpha\n",
    "    quad = ml.q  # 1 HH, 2 LH, 3 LL, 4 HL\n",
    "    labels = np.array([\"Not significant\"]*len(z), dtype=object)\n",
    "    labels[sig & (quad==1)] = \"High-High\"\n",
    "    labels[sig & (quad==2)] = \"Low-High\"\n",
    "    labels[sig & (quad==3)] = \"Low-Low\"\n",
    "    labels[sig & (quad==4)] = \"High-Low\"\n",
    "    return ml, sig, quad, labels\n",
    "\n",
    "# é¢œè‰² & é¡ºåºï¼ˆå››å›¾ç»Ÿä¸€ï¼‰\n",
    "CLRS  = {\"High-High\":\"#d7191c\",\"Low-Low\":\"#2c7bb6\",\"High-Low\":\"#fdae61\",\"Low-High\":\"#abd9e9\",\"Not significant\":\"#e0e0e0\"}\n",
    "ORDER = [\"High-High\",\"Low-Low\",\"High-Low\",\"Low-High\",\"Not significant\"]\n",
    "\n",
    "# ========== è¯»æ•°æ® ==========\n",
    "gdf = gpd.read_file(GEO_PATH)\n",
    "gid = detect_geo_id(gdf)\n",
    "gdf[\"region\"] = gdf[gid].astype(\"string\").str.strip().str.upper()\n",
    "if (not gdf.crs) or gdf.crs.to_epsg()==4326:\n",
    "    gdf = gdf.to_crs(3035)\n",
    "\n",
    "pdf = pd.read_csv(PANEL_PATH, encoding=\"utf-8-sig\")\n",
    "pdf[\"region\"] = pdf[\"region\"].astype(\"string\").str.strip().str.upper()\n",
    "pdf[\"year\"]   = pd.to_numeric(pdf[\"year\"], errors=\"coerce\")\n",
    "for v in VARS:\n",
    "    if v in pdf.columns:\n",
    "        pdf[v] = pd.to_numeric(pdf[v], errors=\"coerce\")\n",
    "\n",
    "# åœ°å›¾èŒƒå›´ä¸€è‡´\n",
    "xmin, ymin, xmax, ymax = gdf.total_bounds\n",
    "\n",
    "# ========== ä¸»å¾ªç¯ ==========\n",
    "for var in VARS:\n",
    "    vdir = OUT_DIR / var\n",
    "    (vdir / \"single_year\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    yearly_maps_all  = []   # å…¨å¹´ï¼š[(year, cache_gdf)]\n",
    "    yearly_maps_rep  = []   # ä»£è¡¨å¹´ï¼š[(year, cache_gdf)]\n",
    "\n",
    "    for yr in YEARS:\n",
    "        d = pdf.loc[pdf[\"year\"]==yr, [\"region\", var]].dropna()\n",
    "        if d.empty:\n",
    "            continue\n",
    "\n",
    "        gg = gdf[[\"region\",\"geometry\"]].merge(d, on=\"region\", how=\"inner\").dropna(subset=[var])\n",
    "        if len(gg) < 5:\n",
    "            continue\n",
    "\n",
    "        # KNN k=6ï¼ˆè¡Œæ ‡å‡†åŒ–ï¼‰\n",
    "        W = KNN.from_dataframe(gg, k=K, use_index=True); W.transform = \"R\"\n",
    "\n",
    "        z = zscore(gg[var].to_numpy())\n",
    "        ml, sig, quad, labels = lisa_cluster_labels(z, W, permutations=PERMUTATIONS, alpha=ALPHA)\n",
    "\n",
    "        # ---- CSV ----\n",
    "        out_tbl = gg[[\"region\"]].copy()\n",
    "        out_tbl[\"Ii\"] = ml.Is\n",
    "        out_tbl[\"p_value\"] = ml.p_sim\n",
    "        out_tbl[\"quadrant\"] = quad\n",
    "        out_tbl[\"significant\"] = sig\n",
    "        out_tbl[\"cluster\"] = labels\n",
    "        csv_path = vdir / f\"lisa_knn6_{var}_{yr}.csv\"\n",
    "        out_tbl.to_csv(csv_path, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "        # ---- å•å¹´åœ°å›¾ï¼ˆä¿ç•™ï¼›å¯ç”¨äºè¡¥å……æˆ–æ£€æŸ¥ï¼‰----\n",
    "        gg_plot = gg.copy()\n",
    "        gg_plot[\"cluster\"] = pd.Categorical(labels, categories=ORDER)\n",
    "        face = gg_plot[\"cluster\"].map(CLRS).fillna(\"#e0e0e0\")\n",
    "        fig, ax = plt.subplots(figsize=(7.2, 6.0))\n",
    "        gg_plot.plot(ax=ax, color=face, edgecolor=\"white\", linewidth=0.2)\n",
    "        ax.set_xlim(xmin, xmax); ax.set_ylim(ymin, ymax)\n",
    "        ax.set_axis_off()\n",
    "        ax.set_title(f\"LISA â€” {var} ({yr})  Î±={ALPHA}, perms={PERMUTATIONS}\\nKNN (k={K}, row-standardized)\", fontsize=11)\n",
    "        import matplotlib.patches as mpatches\n",
    "        handles = [mpatches.Patch(color=CLRS[k], label=k) for k in ORDER]\n",
    "        ax.legend(handles=handles, title=\"Cluster\",\n",
    "                  loc=\"center left\", bbox_to_anchor=(1.02, 0.5),\n",
    "                  frameon=True, fancybox=True, framealpha=0.98)\n",
    "        fig.subplots_adjust(right=0.82)\n",
    "        fig.savefig(vdir / \"single_year\" / f\"lisa_knn6_map_{var}_{yr}.png\", dpi=220, bbox_inches=\"tight\")\n",
    "        plt.close(fig)\n",
    "\n",
    "        # â€”â€” ç¼“å­˜ï¼ˆå…¨å¹´ & ä»£è¡¨å¹´ï¼‰â€”â€”\n",
    "        cache = gg[[\"region\",\"geometry\"]].copy()\n",
    "        cache[\"cluster\"] = pd.Categorical(labels, categories=ORDER).astype(str)\n",
    "        yearly_maps_all.append((yr, cache))\n",
    "        if yr in REP_YEARS:\n",
    "            yearly_maps_rep.append((yr, cache))\n",
    "\n",
    "        print(f\"âœ… {var} {yr}: CSV + PNG done.\")\n",
    "\n",
    "    # ========== æ­£æ–‡ï¼šä»£è¡¨å¹´ 1Ã—3 é¢æ¿ ==========\n",
    "    if len(yearly_maps_rep) > 0:\n",
    "        yearly_maps_rep = sorted(yearly_maps_rep, key=lambda x: x[0])\n",
    "        n = len(yearly_maps_rep)\n",
    "        ncols, nrows = n, 1  # 1Ã—3\n",
    "\n",
    "        # æ¯ä¸ªé¢æ¿å®½åº¦ç•¥å¤§ä¸€äº›ï¼Œä¾¿äºæ­£æ–‡æ”¾å¤§\n",
    "        fig, axes = plt.subplots(nrows, ncols, figsize=(ncols*3.8, nrows*3.6))\n",
    "        if n == 1:\n",
    "            axes = np.array([axes])\n",
    "        axes = np.array(axes).reshape(nrows, ncols)\n",
    "\n",
    "        for i, (yr, cache) in enumerate(yearly_maps_rep):\n",
    "            ax = axes[0, i]\n",
    "            face = cache[\"cluster\"].map(CLRS).fillna(\"#e0e0e0\")\n",
    "            cache.plot(ax=ax, color=face, edgecolor=\"white\", linewidth=0.22)\n",
    "            ax.set_xlim(xmin, xmax); ax.set_ylim(ymin, ymax)\n",
    "            ax.set_title(str(yr), fontsize=12)\n",
    "            ax.set_axis_off()\n",
    "\n",
    "        # å…±ç”¨å›¾ä¾‹ï¼ˆæ•´å¼ å›¾ä¸€ä¸ªï¼‰\n",
    "        import matplotlib.patches as mpatches\n",
    "        handles = [mpatches.Patch(color=CLRS[k], label=k) for k in ORDER]\n",
    "        fig.legend(handles=handles, title=\"Cluster\",\n",
    "                   loc=\"center right\", bbox_to_anchor=(1.02, 0.5),\n",
    "                   frameon=True, fancybox=True, framealpha=0.98)\n",
    "\n",
    "        fig.tight_layout(rect=[0, 0, 0.98, 1])\n",
    "        main_png = OUT_DIR / f\"{var}_LISA_rep_years_{'-'.join(map(str, REP_YEARS))}_knn{K}.png\"\n",
    "        fig.savefig(main_png, dpi=240, bbox_inches=\"tight\")\n",
    "        plt.close(fig)\n",
    "        print(f\"ğŸ“Œ Saved MAIN (1x{n}) LISA figure for {var}: {main_png}\")\n",
    "\n",
    "    # ========== é™„å½•ï¼š10 å¹´ 2Ã—5 é¢æ¿ï¼ˆå¯é€‰ï¼‰ ==========\n",
    "    if MAKE_APPENDIX and len(yearly_maps_all) > 0:\n",
    "        yearly_maps_all = sorted(yearly_maps_all, key=lambda x: x[0])\n",
    "        n = len(yearly_maps_all); ncols = 5; nrows = int(np.ceil(n / ncols))\n",
    "        fig, axes = plt.subplots(nrows, ncols, figsize=(ncols*3.0, nrows*2.8))\n",
    "        axes = np.array(axes).reshape(nrows, ncols)\n",
    "\n",
    "        for i, (yr, cache) in enumerate(yearly_maps_all):\n",
    "            r, c = divmod(i, ncols); ax = axes[r, c]\n",
    "            face = cache[\"cluster\"].map(CLRS).fillna(\"#e0e0e0\")\n",
    "            cache.plot(ax=ax, color=face, edgecolor=\"white\", linewidth=0.18)\n",
    "            ax.set_xlim(xmin, xmax); ax.set_ylim(ymin, ymax)\n",
    "            ax.set_title(str(yr), fontsize=10); ax.set_axis_off()\n",
    "\n",
    "        # å¤šä½™å­å›¾å…³æ‰\n",
    "        for k in range(n, nrows*ncols):\n",
    "            r, c = divmod(k, ncols); axes[r, c].axis(\"off\")\n",
    "\n",
    "        import matplotlib.patches as mpatches\n",
    "        handles = [mpatches.Patch(color=CLRS[k], label=k) for k in ORDER]\n",
    "        fig.legend(handles=handles, title=\"Cluster\",\n",
    "                   loc=\"center right\", bbox_to_anchor=(1.02, 0.5),\n",
    "                   frameon=True, fancybox=True, framealpha=0.98)\n",
    "\n",
    "        fig.tight_layout(rect=[0,0,0.98,1])\n",
    "        grid_png = OUT_DIR / f\"{var}_LISA_grid_2014_2023_knn{K}.png\"\n",
    "        fig.savefig(grid_png, dpi=220, bbox_inches=\"tight\")\n",
    "        plt.close(fig)\n",
    "        print(f\"ğŸ§© Saved APPENDIX (2x5) LISA grid for {var}: {grid_png}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af3fce76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… saved: D:\\Dissertation\\dissertation\\data 2\\data\\Without UK and Germany\\Final\\moran\\lisa_2x2\\employment_rate_LISA_2x2_2014_2018_2020_2023_knn6.png\n",
      "âœ… saved: D:\\Dissertation\\dissertation\\data 2\\data\\Without UK and Germany\\Final\\moran\\lisa_2x2\\unemployment_rate_LISA_2x2_2014_2018_2020_2023_knn6.png\n",
      "âœ… saved: D:\\Dissertation\\dissertation\\data 2\\data\\Without UK and Germany\\Final\\moran\\lisa_2x2\\log_gdp_pc_LISA_2x2_2014_2018_2020_2023_knn6.png\n",
      "âœ… saved: D:\\Dissertation\\dissertation\\data 2\\data\\Without UK and Germany\\Final\\moran\\lisa_2x2\\vet_per_million_LISA_2x2_2014_2018_2020_2023_knn6.png\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "LISA (Local Moran's I) â€” KNN k=6, NUTS2\n",
    "åªç”Ÿæˆï¼šæ¯å˜é‡ 2014/2018/2020/2023 çš„ 2Ã—2 é¢æ¿å›¾ï¼ˆå…±ç”¨å›¾ä¾‹ï¼‰\n",
    "\"\"\"\n",
    "\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from libpysal.weights import KNN\n",
    "from esda.moran import Moran_Local\n",
    "\n",
    "# ========== è·¯å¾„ ==========\n",
    "PANEL_PATH = r\"D:\\Dissertation\\dissertation\\data 2\\data\\Without UK and Germany\\Final\\moran\\filtered_by_islands\\panel_long_no_islands.csv\"\n",
    "GEO_PATH   = r\"D:\\Dissertation\\dissertation\\data 2\\data\\Without UK and Germany\\Final\\moran\\filtered_by_islands\\NUTS2_2021_no_islands.gpkg\"\n",
    "OUT_DIR    = Path(r\"D:\\Dissertation\\dissertation\\data 2\\data\\Without UK and Germany\\Final\\moran\\lisa_2x2\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ========== è®¾ç½® ==========\n",
    "YEARS_2x2    = [2014, 2018, 2020, 2023]     # åªåšè¿™å››å¹´\n",
    "VARS         = [\"employment_rate\", \"unemployment_rate\", \"log_gdp_pc\", \"vet_per_million\"]\n",
    "K            = 6\n",
    "ALPHA        = 0.05\n",
    "PERMUTATIONS = 999\n",
    "\n",
    "# é¢œè‰² & é¡ºåº\n",
    "CLRS  = {\"High-High\":\"#d7191c\",\"Low-Low\":\"#2c7bb6\",\"High-Low\":\"#fdae61\",\n",
    "         \"Low-High\":\"#abd9e9\",\"Not significant\":\"#e0e0e0\"}\n",
    "ORDER = [\"High-High\",\"Low-Low\",\"High-Low\",\"Low-High\",\"Not significant\"]\n",
    "\n",
    "# ========== å·¥å…· ==========\n",
    "def detect_geo_id(gdf: gpd.GeoDataFrame) -> str:\n",
    "    for c in [\"NUTS_ID\",\"nuts_id\",\"NUTS_ID_2021\",\"region\",\"code\",\"id\"]:\n",
    "        if c in gdf.columns: return c\n",
    "    return [c for c in gdf.columns if c != gdf.geometry.name][0]\n",
    "\n",
    "def zscore(x: np.ndarray) -> np.ndarray:\n",
    "    x = x.astype(float)\n",
    "    return (x - x.mean()) / x.std(ddof=0)\n",
    "\n",
    "def lisa_labels(z, W, perms=999, alpha=0.05):\n",
    "    ml = Moran_Local(z, W, permutations=perms)\n",
    "    sig  = ml.p_sim < alpha\n",
    "    quad = ml.q  # 1 HH, 2 LH, 3 LL, 4 HL\n",
    "    lab = np.array([\"Not significant\"]*len(z), dtype=object)\n",
    "    lab[sig & (quad==1)] = \"High-High\"\n",
    "    lab[sig & (quad==2)] = \"Low-High\"\n",
    "    lab[sig & (quad==3)] = \"Low-Low\"\n",
    "    lab[sig & (quad==4)] = \"High-Low\"\n",
    "    return lab\n",
    "\n",
    "# ========== è¯»æ•°æ® ==========\n",
    "gdf = gpd.read_file(GEO_PATH)\n",
    "gid = detect_geo_id(gdf)\n",
    "gdf[\"region\"] = gdf[gid].astype(\"string\").str.strip().str.upper()\n",
    "if (not gdf.crs) or gdf.crs.to_epsg()==4326:\n",
    "    gdf = gdf.to_crs(3035)\n",
    "xmin, ymin, xmax, ymax = gdf.total_bounds\n",
    "\n",
    "pdf = pd.read_csv(PANEL_PATH, encoding=\"utf-8-sig\")\n",
    "pdf[\"region\"] = pdf[\"region\"].astype(\"string\").str.strip().str.upper()\n",
    "pdf[\"year\"]   = pd.to_numeric(pdf[\"year\"], errors=\"coerce\")\n",
    "for v in VARS:\n",
    "    if v in pdf.columns:\n",
    "        pdf[v] = pd.to_numeric(pdf[v], errors=\"coerce\")\n",
    "\n",
    "# ========== ç”Ÿæˆ 2Ã—2 é¢æ¿ ==========\n",
    "for var in VARS:\n",
    "    caches = []\n",
    "    for yr in YEARS_2x2:\n",
    "        d = pdf.loc[pdf[\"year\"]==yr, [\"region\", var]].dropna()\n",
    "        gg = gdf[[\"region\",\"geometry\"]].merge(d, on=\"region\", how=\"inner\").dropna(subset=[var])\n",
    "        if len(gg) < 5:\n",
    "            raise ValueError(f\"{var} {yr}: æœ‰æ•ˆåœ°åŒºè¿‡å°‘ã€‚\")\n",
    "        W = KNN.from_dataframe(gg, k=K, use_index=True); W.transform = \"R\"\n",
    "        z = zscore(gg[var].to_numpy())\n",
    "        labels = lisa_labels(z, W, perms=PERMUTATIONS, alpha=ALPHA)\n",
    "        cache = gg[[\"region\",\"geometry\"]].copy()\n",
    "        cache[\"cluster\"] = pd.Categorical(labels, categories=ORDER).astype(str)\n",
    "        caches.append((yr, cache))\n",
    "\n",
    "    # ç”» 2Ã—2ï¼ˆé¡ºåºæŒ‰ YEARS_2x2ï¼‰\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(10, 8))\n",
    "    axes = axes.reshape(2, 2)\n",
    "    for ax, (yr, cache) in zip(axes.ravel(), caches):\n",
    "        face = cache[\"cluster\"].map(CLRS).fillna(\"#e0e0e0\")\n",
    "        cache.plot(ax=ax, color=face, edgecolor=\"white\", linewidth=0.22)\n",
    "        ax.set_xlim(xmin, xmax); ax.set_ylim(ymin, ymax)\n",
    "        ax.set_title(str(yr), fontsize=14, pad=6)\n",
    "        ax.set_axis_off()\n",
    "\n",
    "    # å…±ç”¨å›¾ä¾‹ï¼ˆå³ä¾§ï¼‰\n",
    "    import matplotlib.patches as mpatches\n",
    "    handles = [mpatches.Patch(color=CLRS[k], label=k) for k in ORDER]\n",
    "    fig.legend(handles=handles, title=\"Cluster\",\n",
    "               loc=\"center right\", bbox_to_anchor=(1.02, 0.5),\n",
    "               frameon=True, fancybox=True, framealpha=0.98)\n",
    "\n",
    "    fig.tight_layout(rect=[0,0,0.98,1])\n",
    "    out_png = OUT_DIR / f\"{var}_LISA_2x2_{YEARS_2x2[0]}_{YEARS_2x2[1]}_{YEARS_2x2[2]}_{YEARS_2x2[3]}_knn{K}.png\"\n",
    "    fig.savefig(out_png, dpi=240, bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "    print(\"âœ… saved:\", out_png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ee1ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "LISA (Local Moran's I) â€” KNN k=6, NUTS2\n",
    "åªç”Ÿæˆï¼šæ¯å˜é‡ 2014/2018/2020/2023 çš„ 2Ã—2 é¢æ¿å›¾ï¼ˆå…±ç”¨å›¾ä¾‹ã€å¹´ä»½å±…ä¸­ï¼‰\n",
    "æ ·å¼ä¸ç¤ºä¾‹å›¾ä¸€è‡´ã€‚\n",
    "\"\"\"\n",
    "\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from libpysal.weights import KNN\n",
    "from esda.moran import Moran_Local\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "# ========== è·¯å¾„ï¼ˆæŒ‰ä½ çš„å·¥ç¨‹ä¿®æ”¹ï¼‰ ==========\n",
    "PANEL_PATH = r\"D:\\Dissertation\\dissertation\\data 2\\data\\Without UK and Germany\\Final\\moran\\filtered_by_islands\\panel_long_no_islands.csv\"\n",
    "GEO_PATH   = r\"D:\\Dissertation\\dissertation\\data 2\\data\\Without UK and Germany\\Final\\moran\\filtered_by_islands\\NUTS2_2021_no_islands.gpkg\"\n",
    "OUT_DIR    = Path(r\"D:\\Dissertation\\dissertation\\data 2\\data\\Without UK and Germany\\Final\\moran\\lisa_2x2\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ========== è®¾ç½® ==========\n",
    "YEARS_2x2    = [2014, 2018, 2020, 2023]               # åªåšè¿™å››å¹´\n",
    "VARS         = [\"employment_rate\", \"unemployment_rate\", \"log_gdp_pc\", \"vet_per_million\"]\n",
    "K            = 6\n",
    "ALPHA        = 0.05\n",
    "PERMUTATIONS = 999\n",
    "\n",
    "# é¢œè‰² & é¡ºåº\n",
    "CLRS  = {\n",
    "    \"High-High\":      \"#d7191c\",\n",
    "    \"Low-Low\":        \"#2c7bb6\",\n",
    "    \"High-Low\":       \"#fdae61\",\n",
    "    \"Low-High\":       \"#abd9e9\",\n",
    "    \"Not significant\": \"#e0e0e0\",\n",
    "}\n",
    "ORDER = [\"High-High\", \"Low-Low\", \"High-Low\", \"Low-High\", \"Not significant\"]\n",
    "\n",
    "# ========== å·¥å…· ==========\n",
    "def detect_geo_id(gdf: gpd.GeoDataFrame) -> str:\n",
    "    for c in [\"region\", \"NUTS_ID\", \"nuts_id\", \"NUTS_ID_2021\", \"NUTS2_ID\", \"NUTS_CODE\", \"code\", \"id\"]:\n",
    "        if c in gdf.columns:\n",
    "            return c\n",
    "    # å…œåº•ï¼šå–ç¬¬ä¸€ä¸ªé geometry åˆ—\n",
    "    return [c for c in gdf.columns if c != gdf.geometry.name][0]\n",
    "\n",
    "\n",
    "def zscore(x: np.ndarray) -> np.ndarray:\n",
    "    x = x.astype(float)\n",
    "    return (x - x.mean()) / x.std(ddof=0)\n",
    "\n",
    "\n",
    "def lisa_labels(z, W, perms=999, alpha=0.05):\n",
    "    ml = Moran_Local(z, W, permutations=perms)\n",
    "    sig  = ml.p_sim < alpha\n",
    "    quad = ml.q  # 1 HH, 2 LH, 3 LL, 4 HL\n",
    "    lab = np.array([\"Not significant\"] * len(z), dtype=object)\n",
    "    lab[sig & (quad == 1)] = \"High-High\"\n",
    "    lab[sig & (quad == 2)] = \"Low-High\"\n",
    "    lab[sig & (quad == 3)] = \"Low-Low\"\n",
    "    lab[sig & (quad == 4)] = \"High-Low\"\n",
    "    return lab\n",
    "\n",
    "# ========== è¯»æ•°æ® ==========\n",
    "gdf = gpd.read_file(GEO_PATH)\n",
    "gid = detect_geo_id(gdf)\n",
    "# ç»Ÿä¸€ ID åˆ—åä¸º regionï¼ˆå¤§å†™å»ç©ºæ ¼ï¼‰\n",
    "gdf[\"region\"] = gdf[gid].astype(\"string\").str.strip().str.upper()\n",
    "# æŠ•å½±ï¼šè‹¥æ—  CRS æˆ–æ˜¯ WGS84ï¼Œåˆ™è½¬åˆ° 3035ï¼Œä¾¿äºæ¬§ç›Ÿåœ°å›¾æ˜¾ç¤º\n",
    "if (not gdf.crs) or gdf.crs.to_epsg() == 4326:\n",
    "    gdf = gdf.to_crs(3035)\n",
    "# å›ºå®šç»Ÿä¸€è§†çª—ï¼Œä¿è¯ 2Ã—2 å››å¹…å›¾å¯¹é½\n",
    "xmin, ymin, xmax, ymax = gdf.total_bounds\n",
    "\n",
    "# é¢æ¿æ•°æ®\n",
    "pdf = pd.read_csv(PANEL_PATH, encoding=\"utf-8-sig\")\n",
    "pdf[\"region\"] = pdf[\"region\"].astype(\"string\").str.strip().str.upper()\n",
    "pdf[\"year\"]   = pd.to_numeric(pdf[\"year\"], errors=\"coerce\")\n",
    "for v in VARS:\n",
    "    if v in pdf.columns:\n",
    "        pdf[v] = pd.to_numeric(pdf[v], errors=\"coerce\")\n",
    "\n",
    "# ========== ç”Ÿæˆ 2Ã—2 é¢æ¿ ==========\n",
    "for var in VARS:\n",
    "    caches = []\n",
    "    for yr in YEARS_2x2:\n",
    "        d = pdf.loc[pdf[\"year\"] == yr, [\"region\", var]].dropna()\n",
    "        gg = gdf[[\"region\", \"geometry\"]].merge(d, on=\"region\", how=\"inner\").dropna(subset=[var])\n",
    "        if len(gg) < max(5, K + 1):\n",
    "            raise ValueError(f\"{var} {yr}: æœ‰æ•ˆåœ°åŒºè¿‡å°‘ï¼ˆ{len(gg)} < {max(5, K+1)}ï¼‰ã€‚\")\n",
    "        # åŸºäº dataframe æ„å»º KNNï¼ˆä½¿ç”¨ç´¢å¼•ä½œä¸º IDï¼‰\n",
    "        W = KNN.from_dataframe(gg, k=K, use_index=True)\n",
    "        W.transform = \"R\"\n",
    "        z = zscore(gg[var].to_numpy())\n",
    "        labels = lisa_labels(z, W, perms=PERMUTATIONS, alpha=ALPHA)\n",
    "        cache = gg[[\"region\", \"geometry\"]].copy()\n",
    "        cache[\"cluster\"] = pd.Categorical(labels, categories=ORDER).astype(str)\n",
    "        caches.append((yr, cache))\n",
    "\n",
    "    # ç”» 2Ã—2ï¼ˆé¡ºåºæŒ‰ YEARS_2x2ï¼‰\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(10, 8))\n",
    "    for ax, (yr, cache) in zip(axes.ravel(), caches):\n",
    "        face = cache[\"cluster\"].map(CLRS).fillna(\"#e0e0e0\")\n",
    "        cache.plot(ax=ax, color=face, edgecolor=\"white\", linewidth=0.22)\n",
    "        ax.set_xlim(xmin, xmax)\n",
    "        ax.set_ylim(ymin, ymax)\n",
    "        ax.set_title(str(yr), fontsize=14, pad=6)\n",
    "        ax.set_axis_off()\n",
    "\n",
    "    # å…±ç”¨å›¾ä¾‹ï¼ˆå³ä¾§ï¼‰\n",
    "    handles = [mpatches.Patch(color=CLRS[k], label=k) for k in ORDER]\n",
    "    fig.legend(\n",
    "        handles=handles,\n",
    "        title=\"Cluster\",\n",
    "        loc=\"center right\",\n",
    "        bbox_to_anchor=(1.02, 0.5),\n",
    "        frameon=True,\n",
    "        fancybox=True,\n",
    "        framealpha=0.98,\n",
    "    )\n",
    "\n",
    "    fig.tight_layout(rect=[0, 0, 0.98, 1])\n",
    "    out_png = OUT_DIR / f\"{var}_LISA_2x2_{YEARS_2x2[0]}_{YEARS_2x2[1]}_{YEARS_2x2[2]}_{YEARS_2x2[3]}_knn{K}.png\"\n",
    "    fig.savefig(out_png, dpi=240, bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "    print(\"âœ… saved:\", out_png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3409d737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… saved: D:\\Dissertation\\dissertation\\data 2\\data\\Without UK and Germany\\Final\\moran\\lisa_2x2\\employment_rate_LISA_2x2_2014_2018_2020_2023_knn6.png\n",
      "âœ… saved: D:\\Dissertation\\dissertation\\data 2\\data\\Without UK and Germany\\Final\\moran\\lisa_2x2\\unemployment_rate_LISA_2x2_2014_2018_2020_2023_knn6.png\n",
      "âœ… saved: D:\\Dissertation\\dissertation\\data 2\\data\\Without UK and Germany\\Final\\moran\\lisa_2x2\\log_gdp_pc_LISA_2x2_2014_2018_2020_2023_knn6.png\n",
      "âœ… saved: D:\\Dissertation\\dissertation\\data 2\\data\\Without UK and Germany\\Final\\moran\\lisa_2x2\\vet_per_million_LISA_2x2_2014_2018_2020_2023_knn6.png\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "LISA (Local Moran's I) â€” KNN k=6, NUTS2\n",
    "åªç”Ÿæˆï¼šæ¯å˜é‡ 2014/2018/2020/2023 çš„ 2Ã—2 é¢æ¿å›¾ï¼ˆå…±ç”¨å›¾ä¾‹ï¼Œå¹´ä»½å±…ä¸­ï¼‰\n",
    "\"\"\"\n",
    "\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from libpysal.weights import KNN\n",
    "from esda.moran import Moran_Local\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "# ========= è·¯å¾„ =========\n",
    "PANEL_PATH = r\"D:\\Dissertation\\dissertation\\data 2\\data\\Without UK and Germany\\Final\\moran\\filtered_by_islands\\panel_long_no_islands.csv\"\n",
    "GEO_PATH   = r\"D:\\Dissertation\\dissertation\\data 2\\data\\Without UK and Germany\\Final\\moran\\filtered_by_islands\\NUTS2_2021_no_islands.gpkg\"\n",
    "OUT_DIR    = Path(r\"D:\\Dissertation\\dissertation\\data 2\\data\\Without UK and Germany\\Final\\moran\\lisa_2x2\")\n",
    "\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ========= è®¾ç½® =========\n",
    "YEARS_2x2    = [2014, 2018, 2020, 2023]   # åªåšè¿™å››å¹´\n",
    "VARS         = [\"employment_rate\", \"unemployment_rate\", \"log_gdp_pc\", \"vet_per_million\"]\n",
    "K            = 6\n",
    "ALPHA        = 0.05\n",
    "PERMUTATIONS = 999\n",
    "\n",
    "# é¢œè‰² & é¡ºåºï¼ˆä¸ç¤ºä¾‹ä¸€è‡´ï¼‰\n",
    "CLRS  = {\n",
    "    \"High-High\":       \"#d7191c\",\n",
    "    \"Low-Low\":         \"#2c7bb6\",\n",
    "    \"High-Low\":        \"#fdae61\",\n",
    "    \"Low-High\":        \"#abd9e9\",\n",
    "    \"Not significant\": \"#e0e0e0\",\n",
    "}\n",
    "ORDER = [\"High-High\", \"Low-Low\", \"High-Low\", \"Low-High\", \"Not significant\"]\n",
    "\n",
    "plt.rcParams.update({\"figure.dpi\": 180, \"savefig.dpi\": 240})\n",
    "\n",
    "# ========= å·¥å…· =========\n",
    "def detect_geo_id(gdf: gpd.GeoDataFrame) -> str:\n",
    "    for c in [\"NUTS_ID\", \"nuts_id\", \"NUTS_ID_2021\", \"region\", \"code\", \"id\"]:\n",
    "        if c in gdf.columns:\n",
    "            return c\n",
    "    # å…œåº•ï¼šå–ç¬¬ä¸€ä¸ªé geometry åˆ—\n",
    "    return [c for c in gdf.columns if c != gdf.geometry.name][0]\n",
    "\n",
    "def zscore(x: np.ndarray) -> np.ndarray:\n",
    "    x = x.astype(float)\n",
    "    return (x - x.mean()) / x.std(ddof=0)\n",
    "\n",
    "def lisa_labels(z, W, perms=999, alpha=0.05):\n",
    "    ml = Moran_Local(z, W, permutations=perms)\n",
    "    sig  = ml.p_sim < alpha\n",
    "    quad = ml.q  # 1 HH, 2 LH, 3 LL, 4 HL\n",
    "    lab = np.array([\"Not significant\"] * len(z), dtype=object)\n",
    "    lab[sig & (quad == 1)] = \"High-High\"\n",
    "    lab[sig & (quad == 2)] = \"Low-High\"\n",
    "    lab[sig & (quad == 3)] = \"Low-Low\"\n",
    "    lab[sig & (quad == 4)] = \"High-Low\"\n",
    "    return lab\n",
    "\n",
    "# ========= è¯»æ•°æ® =========\n",
    "gdf = gpd.read_file(GEO_PATH)\n",
    "gid = detect_geo_id(gdf)\n",
    "gdf[\"region\"] = gdf[gid].astype(\"string\").str.strip().str.upper()\n",
    "\n",
    "# æŠ•å½±ä¸€è‡´ï¼ˆè‹¥æ˜¯WGS84æˆ–æ— CRSåˆ™è½¬ 3035ï¼‰\n",
    "if (not gdf.crs) or gdf.crs.to_epsg() == 4326:\n",
    "    gdf = gdf.to_crs(3035)\n",
    "\n",
    "# ç»Ÿä¸€å¯è§†èŒƒå›´ï¼Œä¿è¯å››å›¾å¯¹é½\n",
    "xmin, ymin, xmax, ymax = gdf.total_bounds\n",
    "\n",
    "pdf = pd.read_csv(PANEL_PATH, encoding=\"utf-8-sig\")\n",
    "pdf[\"region\"] = pdf[\"region\"].astype(\"string\").str.strip().str.upper()\n",
    "pdf[\"year\"]   = pd.to_numeric(pdf[\"year\"], errors=\"coerce\")\n",
    "for v in VARS:\n",
    "    if v in pdf.columns:\n",
    "        pdf[v] = pd.to_numeric(pdf[v], errors=\"coerce\")\n",
    "\n",
    "# ========= ç”Ÿæˆ 2Ã—2 é¢æ¿ =========\n",
    "for var in VARS:\n",
    "    caches = []\n",
    "    for yr in YEARS_2x2:\n",
    "        d = pdf.loc[pdf[\"year\"] == yr, [\"region\", var]].dropna()\n",
    "        gg = gdf[[\"region\", \"geometry\"]].merge(d, on=\"region\", how=\"inner\").dropna(subset=[var])\n",
    "        if len(gg) < max(5, K + 1):\n",
    "            raise ValueError(f\"{var} {yr}: æœ‰æ•ˆåœ°åŒºè¿‡å°‘ï¼ˆ{len(gg)} < {max(5, K+1)}ï¼‰ã€‚\")\n",
    "\n",
    "        # ç”¨å‡ ä½•ç›´æ¥æ„å»º KNN æƒé‡ï¼›è¡Œæ ‡å‡†åŒ–\n",
    "        W = KNN.from_dataframe(gg, k=K, use_index=True)\n",
    "        W.transform = \"R\"\n",
    "\n",
    "        z = zscore(gg[var].to_numpy())\n",
    "        labels = lisa_labels(z, W, perms=PERMUTATIONS, alpha=ALPHA)\n",
    "\n",
    "        cache = gg[[\"region\", \"geometry\"]].copy()\n",
    "        cache[\"cluster\"] = pd.Categorical(labels, categories=ORDER).astype(str)\n",
    "        caches.append((yr, cache))\n",
    "\n",
    "    # ç”» 2Ã—2ï¼ˆé¡ºåºæŒ‰ YEARS_2x2ï¼‰\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(10, 8))\n",
    "    for ax, (yr, cache) in zip(axes.ravel(), caches):\n",
    "        face = cache[\"cluster\"].map(CLRS).fillna(\"#e0e0e0\")\n",
    "        cache.plot(ax=ax, color=face, edgecolor=\"white\", linewidth=0.22)\n",
    "        ax.set_xlim(xmin, xmax); ax.set_ylim(ymin, ymax)\n",
    "        ax.set_title(str(yr), fontsize=14, pad=6)\n",
    "        ax.set_axis_off()\n",
    "\n",
    "    # å…±ç”¨å›¾ä¾‹ï¼ˆå³ä¾§ï¼Œå¡ç‰‡æ ·å¼ï¼‰\n",
    "    handles = [mpatches.Patch(color=CLRS[k], label=k) for k in ORDER]\n",
    "    fig.legend(handles=handles, title=\"Cluster\",\n",
    "               loc=\"center right\", bbox_to_anchor=(1.02, 0.5),\n",
    "               frameon=True, fancybox=True, framealpha=0.98)\n",
    "\n",
    "    fig.tight_layout(rect=[0, 0, 0.98, 1])\n",
    "    out_png = OUT_DIR / f\"{var}_LISA_2x2_{YEARS_2x2[0]}_{YEARS_2x2[1]}_{YEARS_2x2[2]}_{YEARS_2x2[3]}_knn{K}.png\"\n",
    "    fig.savefig(out_png, dpi=240, bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "    print(\"âœ… saved:\", out_png)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
